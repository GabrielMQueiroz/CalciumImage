{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrTvnFc--V59"
   },
   "source": [
    "# **CAIMAN pipeline CNMF-E for miniscope data**\n",
    "\n",
    "**colab_pipeline_cnmfE_V6.ipynb**\n",
    "\n",
    "**Version: 0.4**\n",
    "\n",
    "**caiman v.1.8.9**\n",
    "\n",
    "This Colab Notebook is based on the script demo_pipeline_cnmfE.ipnb (available on caiman github) and has been designed to analyze one photon miniscope V3, calcium imaging directly on the cloud. It relies on a google drive, CaImAn, which itself uses NormCorre for motion correction as well as Constrained Non-Negative Matrix Factorization (CNMF/CNMFE) for source extraction.\n",
    "\n",
    "Contact: george@neuro.ufrn.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sldeiBmBUOc"
   },
   "source": [
    "# Access to GoogleDrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEVQ1yc0A8q4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!ls $path_to_analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9cqYE71CC-u"
   },
   "source": [
    "# Get informations about the virtual machine being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtyjWJr0CMEn"
   },
   "outputs": [],
   "source": [
    "# Disk information\n",
    "#df -h\n",
    "# CPU information\n",
    "#lscpu | grep \"MHz\"\n",
    "# If using a GPU\n",
    "#!nvidia-smi -L\n",
    "#!nvcc --version\n",
    "# Memory information\n",
    "#!cat /proc/meminfo | grep 'MemAvailable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1p5CoCM15ouP"
   },
   "outputs": [],
   "source": [
    "!pip install imageio==2.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EC-s6A0qDBAe"
   },
   "source": [
    "# Install CAIMAN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "glU4cJyuC7Sm",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "#%%capture [--no-stderr] [--no-stdout] [--no-display] [output]  # just for reference...\n",
    "\n",
    "# Clone CaImAn from Github\n",
    "!git clone https://github.com/flatironinstitute/CaImAn.git\n",
    "\n",
    "!pip install h5py==2.10.0\n",
    "\n",
    "# Install relevant packages\n",
    "%cd /content/CaImAn\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Install CaImAn package\n",
    "!ip install -e .\n",
    "\n",
    "#!git checkout e695785\n",
    "# Install CaImAn manager for relevant datasets\n",
    "!python caimanmanager.py install --inplace\n",
    "\n",
    "!pip install -q moviepy\n",
    "!apt install imagemagick\n",
    "#!pip install imageio==2.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "sRTYKfHh5ou4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q moviepy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "riMIceAg5ovF"
   },
   "outputs": [],
   "source": [
    "pip install h5py==2.10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "id": "z2uGTXiO5ovN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement imageio_download_bin (from versions: none)\n",
      "ERROR: No matching distribution found for imageio_download_bin\n"
     ]
    }
   ],
   "source": [
    "pip install imageio_download_bin ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dzpzt8H5ova"
   },
   "source": [
    "# Pr√© Trauma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6WUrgwdQaHVL"
   },
   "source": [
    "# ... and import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_MxiY6S4CAYZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AetherCheeta\\AppData\\Local\\Temp\\ipykernel_3600\\2131185450.py:20: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic('load_ext autoreload')\n",
      "C:\\Users\\AetherCheeta\\AppData\\Local\\Temp\\ipykernel_3600\\2131185450.py:21: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic('autoreload 2')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"fee34b19-b8ba-4607-ba53-c1f4db40c37c\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"fee34b19-b8ba-4607-ba53-c1f4db40c37c\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.7.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"fee34b19-b8ba-4607-ba53-c1f4db40c37c\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "  > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.7.3'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.7.5/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.7.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.7.3.min.js\", \"https://cdn.holoviz.org/panel/1.7.5/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        let retries = 0;\n        const open = () => {\n          if (comm.active) {\n            comm.open();\n          } else if (retries > 3) {\n            console.warn('Comm target never activated')\n          } else {\n            retries += 1\n            setTimeout(open, 500)\n          }\n        }\n        if (comm.active) {\n          comm.open();\n        } else {\n          setTimeout(open, 500)\n        }\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        })\n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='d377af2b-562c-4c63-a71c-172b14dd5984'>\n",
       "  <div id=\"a9274db2-5cd8-4802-8c2d-c7f54bd68948\" data-root-id=\"d377af2b-562c-4c63-a71c-172b14dd5984\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"befe58d1-9fa9-476d-9e92-3ec024aba4f7\":{\"version\":\"3.7.3\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"d377af2b-562c-4c63-a71c-172b14dd5984\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"08117cd3-9b5a-4b20-b1b9-14e9ce935bc2\",\"attributes\":{\"plot_id\":\"d377af2b-562c-4c63-a71c-172b14dd5984\",\"comm_id\":\"f56d6a6566fe40ea8a92bf5af7a801cc\",\"client_comm_id\":\"2d7cba9df22f4493bd3771d135747e21\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"JSComponent1\",\"properties\":[{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"ReactComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\",\"properties\":[{\"name\":\"use_shadow_dom\",\"kind\":\"Any\",\"default\":true},{\"name\":\"esm_constants\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"max_notifications\",\"kind\":\"Any\",\"default\":5},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_rendered\",\"kind\":\"Any\",\"default\":false},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"holoviews.plotting.bokeh.raster.HoverModel\",\"properties\":[{\"name\":\"xy\",\"kind\":\"Any\",\"default\":null},{\"name\":\"data\",\"kind\":\"Any\",\"default\":null}]}]}};\n",
       "  var render_items = [{\"docid\":\"befe58d1-9fa9-476d-9e92-3ec024aba4f7\",\"roots\":{\"d377af2b-562c-4c63-a71c-172b14dd5984\":\"a9274db2-5cd8-4802-8c2d-c7f54bd68948\"},\"root_ids\":[\"d377af2b-562c-4c63-a71c-172b14dd5984\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "d377af2b-562c-4c63-a71c-172b14dd5984"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "\n",
       "\n",
       "\n",
       "<div class=\"logo-block\">\n",
       "<a href=\"https://holoviews.org\" target=\"_blank\" title=\"HoloViews 1.21.0\">\n",
       "  <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC' style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "</a>\n",
       "\n",
       "\n",
       "<a href=\"https://bokeh.org\" target=\"_blank\" title=\"Bokeh 3.7.3\">\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'>\n",
       "  </img>\n",
       "</a>\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "<span style=\"float: left; margin-left: 5px; line-height: 15px; cursor: pointer; opacity: 0.7;\"\n",
       "      onmouseover=\"this.style.opacity='1'\"\n",
       "      onmouseout=\"this.style.opacity='0.7'\"\n",
       "      title=\"Extension loaded. This cell output contains code that enables plot interactivity, it should not be removed.\">‚ìò</span>\n",
       "</div>\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# some imports\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imageio\n",
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    "import os\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "#from caiman.motion_correction import MotionCorrect\n",
    "from caiman.motion_correction import motion_correct_oneP_rigid, motion_correct_oneP_nonrigid, MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour,nb_inspect_correlation_pnr\n",
    "from caiman.utils import visualization\n",
    "from caiman.summary_images import local_correlations_movie_offline\n",
    "from scipy.ndimage import center_of_mass\n",
    "from IPython.display import display, clear_output\n",
    "import re\n",
    "import time\n",
    "#from moviepy.editor import VideoFileClip, concatenate_videoclips,clips_array,ipython_display\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import psutil\n",
    "\n",
    "mpl.style.use('default')\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "from scipy import ndimage\n",
    "\n",
    "import bokeh.plotting as bpl\n",
    "bpl.output_notebook()\n",
    "\n",
    "import holoviews as hv\n",
    "from holoviews import opts\n",
    "hv.notebook_extension('bokeh')\n",
    "#hv.extension('bokeh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mXzX6iICWeN"
   },
   "source": [
    "# (step #1) --> Set some experiment parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "A3VsLCxwCj8i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path_to_analyze:   D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma\n",
      "Parameters saved. Ready to start analyzing\n"
     ]
    }
   ],
   "source": [
    "path_to_analyze = r'D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma'\n",
    "folder_to_results = \"Results\"    # Where to save the data\n",
    "spatial_downsample_ratio  = 1/2\n",
    "temporal_downsample_ratio = 1    # max 1\n",
    "frame_rate=10                    # if the decay time (half time) is 0.4s, then for frame_rate=20 means 4 frames of information (half)\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "save_hdf5 = True                      # To save the results in hdf5 format\n",
    "save_mat  = True                      # To save the resuts im matlab format\n",
    "save_motion_corrected_file = True     # To save the corrected movie file --> motion_corrected.avi (may need for mesmerize)\n",
    "remove_background = True              # To remove the background florescence of the videos\n",
    "#alert_gmail = '' # You can leave your Gmail adress to be notified when your analysis is done\n",
    "#alert_gmail_password = '' # Password to your Gmail account\n",
    "\n",
    "print('path_to_analyze:  ',path_to_analyze)\n",
    "print('Parameters saved. Ready to start analyzing')\n",
    "#!ls $path_to_analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "L9Otq9-hJMMj"
   },
   "outputs": [],
   "source": [
    "def plot_results(cnm_obj, num_traces = 10, time_int=0.5, indexes=None):\n",
    "  if indexes is None:\n",
    "    indexes = cnm_obj.estimates.idx_components\n",
    "  indexes = np.random.permutation(indexes)[:num_traces]\n",
    "  masks = np.reshape(cnm_obj.estimates.A.toarray(),cnm_obj.estimates.dims+(-1,), order='F')#.transpose([2,0,1])\n",
    "  masks = masks[indexes]\n",
    "\n",
    "  C = cnm_obj.estimates.C[indexes]\n",
    "  traces = C + cnm_obj.estimates.YrA[indexes]\n",
    "\n",
    "\n",
    "  for i in range(masks.shape[0]):\n",
    "    # fig, axs = plt.subplots(1,2,figsize=(16,6))\n",
    "    fig = plt.figure(constrained_layout=True,figsize=(16,6))\n",
    "    gs = fig.add_gridspec(1, 3)\n",
    "    ax1 = fig.add_subplot(gs[:1])\n",
    "    ax2 = fig.add_subplot(gs[1:])\n",
    "    ax1.imshow(masks[i])\n",
    "    plt.axis('off')\n",
    "    ax2.plot(traces[i], label='traces')\n",
    "    ax2.plot(C[i], label='denoised')\n",
    "    display(fig)\n",
    "    clear_output(wait=True)\n",
    "    plt.pause(time_int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ixv4LQJeCAYm"
   },
   "source": [
    "### Set up logger (optional)\n",
    "You can log to a file using the filename parameter, or make the output more or less verbose by setting level to `logging.DEBUG`, `logging.INFO`, `logging.WARNING`, or `logging.ERROR`. A filename argument can also be passed to store the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XlJO_qOFCAYp"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format= \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UTf3jruyGlhP"
   },
   "source": [
    "# Get information from the experiment\n",
    "This is particularily important to register the date/time and name of the experiment, which are also use to create specific analysis folders containing all the analyzed data (calcium imaging and behavior). Additionnaly, timestamps are retrieved and allow to realign calcium imaging with behavior videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "fCSKPbRCGwgq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis started on 2025-08-01 15:50\n",
      "Directory  D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/  Created\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "analysis_time = now.strftime(\"%Y-%m-%d %H:%M\") # This is to register when the analysis was performed\n",
    "print('Analysis started on ' + analysis_time)\n",
    "\n",
    "analysis_start = time.time() # This is to register the time spent analyzing\n",
    "\n",
    "path_to_results  = path_to_analyze+'/' + folder_to_results + '/'\n",
    "\n",
    "#dirResults = path_to_analyze + folder_to_results\n",
    "#print('Name of the folder for the result: ' + dirResults)\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(path_to_results)\n",
    "    print(\"Directory \" , path_to_results ,  \" Created\")\n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , path_to_results ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIpv3pD7CAYx"
   },
   "source": [
    "## Extract the date/time of the experiment and save as a timestamp variable\n",
    "The date/time values are extracted from the automatic DAQ folder organization (might not work if you renamed your folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "LvOpiczMFfn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not retrieve date information\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  splitname = str.split(path_to_analyze, '/')\n",
    "\n",
    "  dateStrPart = splitname[-3]\n",
    "  timeStrPart = splitname[-2]\n",
    "  #aasd=str.s\n",
    "  date_result = str.split(dateStrPart, '_')\n",
    "  month = int(date_result[0])\n",
    "  day = int(date_result[1])\n",
    "  year = int(date_result[2])\n",
    "\n",
    "  timeStrPart = re.sub('[HSM]','', timeStrPart)\n",
    "  time_result = str.split(timeStrPart,'_')\n",
    "\n",
    "  hour = int(time_result[0])\n",
    "  minute = int(time_result[1])\n",
    "  seconds = int(time_result[2])\n",
    "\n",
    "  experiment_timestamp = datetime.timestamp(datetime(year,month,day,hour,minute,seconds))\n",
    "  #dateNum = date.toordinal(date(year,month,day,hour,minute,seconds))\n",
    "\n",
    "except:\n",
    "  print('Could not retrieve date information')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cp05RfNJFn4b"
   },
   "source": [
    "# Access Google Drive and download miniscope video files\n",
    "\n",
    "##(step #2)  -->  adjust=True\n",
    "\n",
    "##(step #5)  -->  adjust=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YVOE4RXNFrAn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miniscope files in folder:\n",
      "['msCam1.avi', 'msCam2.avi', 'msCam3.avi', 'msCam4.avi', 'msCam5.avi', 'msCam6.avi', 'msCam7.avi', 'msCam8.avi', 'msCam9.avi', 'msCam10.avi', 'msCam11.avi', 'msCam12.avi', 'msCam13.avi', 'msCam14.avi']\n"
     ]
    }
   ],
   "source": [
    "adjust=True\n",
    "\n",
    "sessionFilesResponse = os.listdir(path_to_analyze)\n",
    "filesList = []\n",
    "msFileList = []\n",
    "datFileList = []\n",
    "\n",
    "for file in sessionFilesResponse:\n",
    "  filesList.append(file)\n",
    "\n",
    "for i in filesList[:]:\n",
    "  if i.startswith('ms') and i.endswith('.avi'):\n",
    "    msFileList.append(i)\n",
    "  if i.endswith('.dat'):\n",
    "    datFileList.append(i)\n",
    "\n",
    "msFileList = sorted(msFileList, key=lambda x: int(re.sub('[msCam.avi]','', x)))\n",
    "\n",
    "if adjust:\n",
    "  msFileList = msFileList[0:20]\n",
    "\n",
    "print('Miniscope files in folder:')\n",
    "print(msFileList)\n",
    "msLocalFileList = [path_to_results + s for s in msFileList]\n",
    "\n",
    "if len(msFileList) == 0:\n",
    "  print(\"No miniscope avi files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6SX52iZHZbu"
   },
   "source": [
    "## Copy miniscope videos for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "pKnrxrD55owd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miniscope files in folder:\n",
      "['msCam1.avi', 'msCam2.avi', 'msCam3.avi', 'msCam4.avi', 'msCam5.avi', 'msCam6.avi', 'msCam7.avi', 'msCam8.avi', 'msCam9.avi', 'msCam10.avi', 'msCam11.avi', 'msCam12.avi', 'msCam13.avi', 'msCam14.avi']\n",
      "Files copyed for analysis:\n",
      "['msCam1.avi', 'msCam2.avi', 'msCam3.avi', 'msCam4.avi', 'msCam5.avi', 'msCam6.avi', 'msCam7.avi', 'msCam8.avi', 'msCam9.avi', 'msCam10.avi', 'msCam11.avi', 'msCam12.avi', 'msCam13.avi', 'msCam14.avi']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sessionFilesResponse = os.listdir(path_to_analyze)\n",
    "filesList = []\n",
    "msFileList = []\n",
    "datFileList = []\n",
    "\n",
    "for file in sessionFilesResponse:\n",
    "  filesList.append(file)\n",
    "\n",
    "for i in filesList[:]:\n",
    "  if i.startswith('ms') and i.endswith('.avi'):\n",
    "    msFileList.append(i)\n",
    "  if i.endswith('.dat'):\n",
    "    datFileList.append(i)\n",
    "\n",
    "msFileList = sorted(msFileList, key=lambda x: int(re.sub('[msCam.avi]','', x)))\n",
    "\n",
    "if adjust:\n",
    "  msFileList = msFileList[0:20]\n",
    "\n",
    "print('Miniscope files in folder:')\n",
    "print(msFileList)\n",
    "msLocalFileList = [path_to_results + s for s in msFileList]\n",
    "\n",
    "if len(msFileList) == 0:\n",
    "  print(\"No miniscope avi files found\")\n",
    "\n",
    "  for fname in msFileList:\n",
    "    src = os.path.join(path_to_analyze, fname)\n",
    "    dst = os.path.join(path_to_results, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "for fname in datFileList:\n",
    "    src = os.path.join(path_to_analyze, fname)\n",
    "    dst = os.path.join(path_to_results, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "# Create a list of files downloaded on the virtual machine\n",
    "msLocalFileList = [path_to_results + s for s in msFileList]\n",
    "fnames = msLocalFileList\n",
    "\n",
    "print('Files copyed for analysis:')\n",
    "print(msFileList)\n",
    "print(datFileList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "y79Vui-IHqQX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file msCam1.avi copyed for analysis\n",
      "file msCam2.avi copyed for analysis\n",
      "file msCam3.avi copyed for analysis\n",
      "file msCam4.avi copyed for analysis\n",
      "file msCam5.avi copyed for analysis\n",
      "file msCam6.avi copyed for analysis\n",
      "file msCam7.avi copyed for analysis\n",
      "file msCam8.avi copyed for analysis\n",
      "file msCam9.avi copyed for analysis\n",
      "file msCam10.avi copyed for analysis\n",
      "file msCam11.avi copyed for analysis\n",
      "file msCam12.avi copyed for analysis\n",
      "file msCam13.avi copyed for analysis\n",
      "file msCam14.avi copyed for analysis\n",
      "Files copyed for analysis:\n",
      "['msCam1.avi', 'msCam2.avi', 'msCam3.avi', 'msCam4.avi', 'msCam5.avi', 'msCam6.avi', 'msCam7.avi', 'msCam8.avi', 'msCam9.avi', 'msCam10.avi', 'msCam11.avi', 'msCam12.avi', 'msCam13.avi', 'msCam14.avi']\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for fname in msFileList:\n",
    "    src = os.path.join(path_to_analyze, fname)\n",
    "    dst = os.path.join(path_to_results, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "for fname in datFileList:\n",
    "    src = os.path.join(path_to_analyze, fname)\n",
    "    dst = os.path.join(path_to_results, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "# Create a list of files downloaded on the virtual machine\n",
    "msLocalFileList = [path_to_results + s for s in msFileList]\n",
    "fnames = msLocalFileList\n",
    "\n",
    "print('Files copyed for analysis:')\n",
    "print(msFileList)\n",
    "print(datFileList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShxkE7KOH_f-"
   },
   "source": [
    "## Downsample (spatial and temporal) miniscope videos for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yydo1BTuIMi_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "msCam_original:(1000, 480, 752)\n",
      "msCam_resized: (1000, 240, 376)\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam1.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam2.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam3.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam4.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam5.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam6.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam7.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam8.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam9.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam10.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam11.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam12.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam13.avi --> resized\n",
      "D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/msCam14.avi --> resized\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'D:/Master_Gabriel/Progaming/Calciumdata/Animal1/Pretrauma/Results/clip1.avi'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info=True\n",
    "for fname in msLocalFileList:\n",
    "    msCam = cm.load(fname)\n",
    "    msCam_resized=msCam.resize(spatial_downsample_ratio, spatial_downsample_ratio,temporal_downsample_ratio)\n",
    "    msCam_resized.save(fname)\n",
    "    if info==True:\n",
    "        info=False\n",
    "        print('msCam_original:' + str(msCam.shape))\n",
    "        print('msCam_resized: ' + str(msCam_resized.shape))\n",
    "    print(fname + ' --> resized')\n",
    "#clip1 = VideoFileClip(msLocalFileList[0])\n",
    "#ipython_display(clip1,width=400)\n",
    "clip1_name=path_to_results + \"clip1.avi\"\n",
    "msCam_resized.save(clip1_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "CmAJCvBZGuBG"
   },
   "outputs": [],
   "source": [
    "if remove_background:\n",
    "  msCam_min=[]\n",
    "  for fname in msLocalFileList:\n",
    "    msCam = cm.load(fname)          #pick one video\n",
    "    msCam_min.append(msCam.min(0))  #store the minimum intensity pixels over the time in a frame\n",
    "  tmp=np.array(msCam_min)\n",
    "  template_min=tmp.min(0)             #find the minimum intensity over all frames\n",
    "  template_min2= 0.6*ndimage.uniform_filter(template_min, size=4)\n",
    "\n",
    "  for fname in msLocalFileList:\n",
    "    msCam = cm.load(fname)          #pick one video\n",
    "    msCam = msCam-template_min2\n",
    "\n",
    "    msCam.save(fname)\n",
    "#  video=cm.concatenate([msCam_resized,msCam], axis=2).play(fr=60, q_max=99.5, magnification=1)\n",
    "  clip2_name=path_to_results + \"clip2.avi\"\n",
    "  msCam.save(clip2_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uLRv3WICAY7"
   },
   "source": [
    "## Play the movies (optional)\n",
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "dV4N48EcKiXv"
   },
   "outputs": [],
   "source": [
    "clip1 = VideoFileClip(clip1_name).margin(1)\n",
    "if remove_background:\n",
    "  clip2 = VideoFileClip(clip2_name).margin(1)\n",
    "  final_clip = clips_array([[clip1,clip2]])\n",
    "  clip_width=800\n",
    "else:\n",
    "  final_clip = clip1\n",
    "  clip_width=400\n",
    "ipython_display(final_clip,width=clip_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGx_N1jCWMKI"
   },
   "source": [
    "## Check if the video has been resized (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wRNPE1HdMItd"
   },
   "outputs": [],
   "source": [
    "# Make sure the video has been resized\n",
    "clip = VideoFileClip(msLocalFileList[0])\n",
    "clip.save_frame(path_to_results + 'downsampled_frame.png')\n",
    "\n",
    "img=mpl.image.imread(path_to_results + 'downsampled_frame.png')\n",
    "imgplot = plt.imshow(img); plt.title('Downsampled size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "J71Y0qKl1loe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1418351 [cluster.py:       setup_cluster():225] [3600] The local backend is an alias for the multiprocessing backend, and the alias may be removed in some future version of Caiman\n",
      "Exception in thread Thread-8 (_handle_workers):\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\threading.py\", line 1016, in _bootstrap_inner\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    self.run()\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\multiprocessing\\pool.py\", line 522, in _handle_workers\n",
      "    cls._wait_for_updates(current_sentinels, change_notifier)\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\multiprocessing\\pool.py\", line 502, in _wait_for_updates\n",
      "    wait(sentinels, timeout=timeout)\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\multiprocessing\\connection.py\", line 879, in wait\n",
      "    ready_handles = _exhaustive_wait(waithandle_to_obj.keys(), timeout)\n",
      "  File \"d:\\Anaconda\\envs\\caiman\\lib\\multiprocessing\\connection.py\", line 811, in _exhaustive_wait\n",
      "    res = _winapi.WaitForMultipleObjects(L, False, timeout)\n",
      "ValueError: need at most 63 handles, got a sequence of length 130\n"
     ]
    }
   ],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=128, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q56zMABWZdOq"
   },
   "source": [
    "# Set parameters for motion correction\n",
    "Ideally, optimize these for your datasets then stick to these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqrgyvGV1lr3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1432948 [params.py:       change_params():1166] [3600] In setting CNMFParams, non-pathed parameters were used; this is deprecated. In some future version of Caiman, allow_legacy will default to False (and eventually will be removed)\n",
      "     1432949 [params.py:       change_params():1172] [3600] In setting CNMFParams, provided toplevel key only_init_patch was unused. This is a bug!\n"
     ]
    }
   ],
   "source": [
    "# dataset dependent parameters\n",
    "frate = frame_rate*temporal_downsample_ratio                       # movie frame rate\n",
    "decay_time = decay_time                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (4, 4)      # maximum allowed rigid shift\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (36, 36)      # overlap between patches (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "use_cuda = False         # Set to True in order to use GPU\n",
    "only_init_patch = True\n",
    "memory_fact = 0.8\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "    # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None, # intervals at which patches are laid out for motion correction\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan,\n",
    "    'use_cuda' : use_cuda,\n",
    "    'only_init_patch' : only_init_patch,\n",
    "    'memory_fact': memory_fact\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUE6IoOiZqLV"
   },
   "source": [
    "## Perform motion correction (might take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zE9wFzVg1lye"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     1450940 [motion_correction.py:            __init__():205] [3600] cuda is no longer supported; this kwarg will be removed in a future version of caiman\n",
      "     1451257 [movies.py:      extract_shifts():242] [3600] Movie average is negative. Removing 1st percentile.\n",
      "     1451261 [movies.py:      extract_shifts():260] [3600] Movie average is negative. Removing 1st percentile.\n",
      "     1451399 [movies.py:      extract_shifts():242] [3600] Movie average is negative. Removing 1st percentile.\n",
      "     1451403 [movies.py:      extract_shifts():260] [3600] Movie average is negative. Removing 1st percentile.\n",
      "     1451539 [movies.py:      extract_shifts():242] [3600] Movie average is negative. Removing 1st percentile.\n",
      "     1451543 [movies.py:      extract_shifts():260] [3600] Movie average is negative. Removing 1st percentile.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reduce the size of the data by downsampling\n",
    "spatial_downsample_ratio = 0.5\n",
    "temporal_downsample_ratio = 0.5\n",
    "data=[]\n",
    "# Perform downsampling on the data\n",
    "#downsampled_data = data[::temporal_downsample_ratio, ::spatial_downsample_ratio, ::spatial_downsample_ratio]\n",
    "\n",
    "\n",
    "start = time.time() # This is to keep track of how long the analysis is running\n",
    "if motion_correct:\n",
    "    # do motion correction rigid\n",
    "    mc = MotionCorrect(fnames, dview=dview, **opts.get_group('motion'))\n",
    "    mc.motion_correct(save_movie=True)\n",
    "    fname_mc = mc.fname_tot_els if pw_rigid else mc.fname_tot_rig\n",
    "    if save_motion_corrected_file:\n",
    "      mc_name='motion_corrected.avi'\n",
    "      motion_corrected=cm.load(fname_mc)\n",
    "      motion_corrected.save(path_to_results + mc_name)\n",
    "      print(motion_corrected.shape)\n",
    "      print('The ' + mc_name + ' file has '+ str( int((motion_corrected.nbytes)/(1024*1024))) + ' Mb')\n",
    "end = time.time()\n",
    "print('Motion correction has been done in ' + str(int(end - start)) + ' seconds!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdJfpT-LvPTf"
   },
   "source": [
    "## If motion corrected data exists, use this cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpeSCNbPvN8U",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "sessionFilesResponse = os.listdir(r'C:/Users/IC/Documents/PythonCampScript/pretraumaResults')\n",
    "Dirpaht= r'C:/Users/IC/Documents/PythonCampScript/pretraumaResults'\n",
    "\n",
    "filesList = []\n",
    "fname_new = []\n",
    "\n",
    "for file in sessionFilesResponse:\n",
    "  filesList.append(file)\n",
    "\n",
    "for i in filesList[:]:\n",
    "  if i.startswith('memmap__'):\n",
    "    fname_new=i\n",
    "\n",
    "fname_new= Dirpaht  + '/' + fname_new\n",
    "print(fname_new)\n",
    "\n",
    "bord_px=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9BpW6jU49sEe"
   },
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kxSE_PE5ox6"
   },
   "outputs": [],
   "source": [
    "np.shape(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mfqyIl4ebbmU"
   },
   "source": [
    "## Plot the motion corrected template and associated shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "LVpwufZP1l1J"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "if motion_correct and not pw_rigid:\n",
    "  plt.figure(figsize=(20,10))\n",
    "  plt.subplot(2, 1, 1)\n",
    "  plt.title('Filtered template')\n",
    "  plt.imshow(mc.total_template_rig);  # % plot template\n",
    "  plt.subplot(2, 1, 2)\n",
    "  plt.title('Estimated shifts')\n",
    "  plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
    "  plt.legend(['x shifts', 'y shifts'])\n",
    "  plt.xlabel('frames')\n",
    "  plt.ylabel('pixels')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeu2LCLJbrxc"
   },
   "source": [
    "## Map the motion corrected video to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "umoGXYoS9eqb"
   },
   "outputs": [],
   "source": [
    "if motion_correct:\n",
    "    if pw_rigid:\n",
    "        bord_px = np.ceil(np.maximum(np.max(np.abs(mc.x_shifts_els)),\n",
    "                                     np.max(np.abs(mc.y_shifts_els)))).astype(np.int)\n",
    "    else:\n",
    "        bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
    "\n",
    "    bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C', border_to_0=bord_px)\n",
    "\n",
    "else:  # if no motion correction just memory map the file\n",
    "    fname_new = cm.save_memmap(fnames, base_name='memmap_', order='C', border_to_0=0, dview=dview)\n",
    "\n",
    "print('Motion corrected video has been mapped to memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brCvjpi_9r-e"
   },
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "\n",
    "sessionFilesResponse = os.listdir(path_to_results)\n",
    "filesList = []\n",
    "fname_new = []\n",
    "\n",
    "for file in sessionFilesResponse:\n",
    "  filesList.append(file)\n",
    "\n",
    "for i in filesList[:]:\n",
    "  if i.startswith('memmap__'):\n",
    "    fname_new=i\n",
    "\n",
    "fname_new=path_to_results + fname_new\n",
    "print(fname_new)\n",
    "\n",
    "bord_px=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "auV9qzZQ5oyd"
   },
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "WjqlvdtA5oye"
   },
   "outputs": [],
   "source": [
    "plt.imshow(images[:][::,55:295:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "HblZs5v_5oyk"
   },
   "outputs": [],
   "source": [
    "images=np.array([])\n",
    "for i in range(len(imagest)):\n",
    "    images=np.append(images,imagest[i][::,55:295:])\n",
    "plt.imshow(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "b4u5WZY75oyo"
   },
   "outputs": [],
   "source": [
    "#downsample_factor=int(images[::].shape[0]/500)\n",
    "#print(downsample_factor)\n",
    "#plt.imshow(images[::downsample_factor])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7y8lNmzma8FC"
   },
   "source": [
    "# Inspect summary images and find parameters\n",
    "\n",
    "Check the optimal values of min_corr and min_pnr by looking the histogram in the figure that pops up. You can modify them in the params object. Note that computing the correlation pnr image can be computationally and memory demanding for large datasets. In this case you can compute only on a subset of the data and was set for 500 frames. This will compute the correlation pnr image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMZ07RG6dH_w"
   },
   "source": [
    "## (step #3) --> Optimize the parameter \"gausean_width\" (ussually around 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LkBTMiA45oy0"
   },
   "outputs": [],
   "source": [
    "hv.extension('bokeh')\n",
    "\n",
    "# going to use show() to open plot in browser\n",
    "from bokeh.plotting import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZG6jUYC6IeZ"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "%env HV_DOC_HTML=True\n",
    "# compute some summary images (correlation and peak to noise)\n",
    "\n",
    "gausean_width = 3.0     #gSig... specifies a gausean 2D width for approximating a neuron\n",
    "\n",
    "hv.extension('bokeh')\n",
    "downsample_factor=int(images[::].shape[0]/500)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(images[::downsample_factor], gSig=gausean_width, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "nb_inspect_correlation_pnr(cn_filter, pnr)\n",
    "show(hv.render(nb_inspect_correlation_pnr(cn_filter, pnr)))\n",
    "print(cn_filter.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AINj8_U_kvWC"
   },
   "source": [
    "## (step #4) --> Optimize the parameters \"min_corr and min_pnr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zV7GgDehd3yK"
   },
   "outputs": [],
   "source": [
    "# Now sert the parameters\n",
    "min_corr=0.6 # min correlation of peak (from correlation image)\n",
    "min_pnr =6.5  # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJO_LEG9eMKp"
   },
   "source": [
    "## Parameter setting for CNMF-E\n",
    "We now define some parameters for the source extraction step using the CNMF-E algorithm.\n",
    "We construct a new dictionary and use this to modify the *existing* `params` object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDhkRxDdd8kf"
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "# frate = 10 # movie frame rate\n",
    "decay_time = decay_time  # length of a typical transient in seconds\n",
    "fnames=fnames\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = gSig_filt    # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = max_shifts  # maximum allowed rigid shift\n",
    "strides = strides       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = overlaps      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = max_deviation_rigid  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fZGHi2Ad8nr"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# parameters for source extraction and deconvolution\n",
    "av_diameter=4*gausean_width+1\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None\n",
    "gSig = (gausean_width, gausean_width)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = (av_diameter, av_diameter)     # average diameter of a neuron, in general 4*gSig+1\n",
    "Ain = None          # possibility to seed with predetermined binary masks\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb= 0: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb<-1: Don't return background\n",
    "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "#                     else it is set automatically\n",
    "min_corr = min_corr       # min peak value from correlation image\n",
    "min_pnr  = min_pnr       # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use 'corr_pnr' for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': bord_px})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DfE2nL1Zd8qo"
   },
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPN_9LABe_0p"
   },
   "source": [
    "# Perform CNMFe extraction\n",
    "This will take a while. Coffee time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2JZra4Mkpws"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FGekpOxFfCHR"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "start = time.time()\n",
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "cnm.fit(images)\n",
    "end = time.time()\n",
    "TotalTime=(end-start)/60\n",
    "\n",
    "print(f'CNMFe has been done in {TotalTime}   minutes!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apRYLVauewJR"
   },
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "After setting some parameters we again modify the existing `params` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c7sgNbZHq6kJ"
   },
   "source": [
    "## (step #6) --> Optimize the parameters min_SNR and r_values_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ZnIxFoxI5U"
   },
   "outputs": [],
   "source": [
    "ls /root/caiman_data/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69XkpUdHCHth"
   },
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 3.0            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.80   # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cF4Y1iG66sCM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "#How many neurons to plot\n",
    "neuronsToPlot = 150\n",
    "\n",
    "DeconvTraces = cnm.estimates.S     #\n",
    "RawTraces = cnm.estimates.C        #denoised component\n",
    "SFP1 = cnm.estimates.A\n",
    "SFP = cnm.estimates.A\n",
    "\n",
    "SFP_dims = list(dims)\n",
    "SFP_dims.append(SFP.shape[1])\n",
    "print('Spatial foootprints dimensions (height x width x neurons): ' + str(SFP_dims))\n",
    "\n",
    "#numNeurons = SFP_dims[2]\n",
    "idx_good=cnm.estimates.idx_components\n",
    "numNeurons = len(idx_good)\n",
    "\n",
    "SFP = np.reshape(SFP.toarray(), SFP_dims, order='F')\n",
    "\n",
    "maxRawTraces = np.amax(RawTraces)\n",
    "\n",
    "plt.figure(figsize=(30,15))\n",
    "plt.subplot(3,2,1); plt.imshow(cn_filter); plt.colorbar(); plt.title('Correlation projection')\n",
    "plt.subplot(3,2,3); plt.imshow(pnr); plt.colorbar(); plt.title('PNR')\n",
    "plt.subplot(3,2,5); plt.imshow(np.amax(SFP,axis=2)); plt.colorbar(); plt.title('Spatial footprints')\n",
    "\n",
    "plt.subplot(2,2,2); plt.title('Example traces (first '+str(neuronsToPlot) + ' cells). Found '+str(numNeurons)+' neurons')\n",
    "\n",
    "plot_gain = 5 # To change the value gain of traces\n",
    "if numNeurons >= neuronsToPlot:\n",
    "  for i in range(neuronsToPlot):\n",
    "    if i == 0:\n",
    "      plt.plot(RawTraces[idx_good[i],:],'k')\n",
    "    else:\n",
    "      trace = RawTraces[idx_good[i],:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "else:\n",
    "  for i in range(numNeurons):\n",
    "    if i == 0:\n",
    "      plt.plot(RawTraces[idx_good[i],:],'k')\n",
    "    else:\n",
    "      trace = RawTraces[idx_good[i],:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "#plt.subplots_adjust(top=1.02, bottom=0.00, left=0.0, right=0.5, hspace=0.25, wspace=0.35)\n",
    "plt.show\n",
    "\n",
    "plt.subplot(2,2,4); plt.figure; plt.title('Deconvolved traces (first '+str(neuronsToPlot) + ' cells). Found '+str(numNeurons)+' neurons')\n",
    "plot_gain = 20 # To change the value gain of traces\n",
    "if numNeurons >= neuronsToPlot:\n",
    "  for i in range(neuronsToPlot):\n",
    "    if i == 0:\n",
    "      plt.plot(DeconvTraces[idx_good[i],:],'k')\n",
    "    else:\n",
    "      trace = DeconvTraces[idx_good[i],:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "else:\n",
    "  for i in range(numNeurons):\n",
    "    if i == 0:\n",
    "      plt.plot(DeconvTraces[idx_good[i],:],'k')\n",
    "    else:\n",
    "      trace = DeconvTraces[idx_good[i],:] + maxRawTraces*i/plot_gain\n",
    "      plt.plot(trace,'k')\n",
    "\n",
    "# Save summary figure\n",
    "plt.savefig(path_to_results + '/' + 'summary_figure.svg', edgecolor='w', format='svg', transparent=True)\n",
    "plt.savefig(path_to_results + '/' + 'summary_figure.jpg', edgecolor='w', format='jpg', transparent=True)\n",
    "#print(path_to_results)\n",
    "plt.imsave(path_to_results+'/PnrResult.jpg',arr=pnr)\n",
    "#imgpnr=plt.imread(pnr)\n",
    "plt.show()\n",
    "plt.imshow(pnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEJmlKW55ozi"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 5, figsize=(20, 10), constrained_layout=True)\n",
    "cont = 10\n",
    "x = np.linspace(0,1,len(RawTraces[0]))\n",
    "if cont<150:\n",
    "\n",
    "    for ax, index in zip(axs.flat, idx_good):\n",
    "        ax.set_title(f'ID={index}')\n",
    "        ax.plot(x, cnm.estimates.C[cont], lw=0.9)\n",
    "        cont +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mxDwMtsF5ozl"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 5, figsize=(20, 10), constrained_layout=True)\n",
    "cont = 10\n",
    "x = np.linspace(0,1,len(RawTraces[0]))\n",
    "if cont<100:\n",
    "\n",
    "    for ax, index in zip(axs.flat, idx_good):\n",
    "        ax.set_title(f'ID={index}')\n",
    "        ax.plot(x, cnm.estimates.C[cont], lw=0.9)\n",
    "        cont +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AeJQdfXq5ozn"
   },
   "outputs": [],
   "source": [
    "len(cnm.estimates.S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BN_Tks5c5ozq"
   },
   "outputs": [],
   "source": [
    "#display(cnm.estimates.C)\n",
    "print(np.shape(RawTraces))\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlim(0,1)\n",
    "ax.plot(np.linspace(0,1,10999+1),RawTraces[58])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAM0456w5ozu"
   },
   "outputs": [],
   "source": [
    "np.shape(cn_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RWx9ywpZ5ozy"
   },
   "outputs": [],
   "source": [
    "print(np.shape(Yr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGq4fKt7hpiJ"
   },
   "source": [
    "## Accepted components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "gdz9lKWwezFX"
   },
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm.estimates.nb_view_components(images,img=pnr,\n",
    "                                denoised_color='red', cmap='viridis',thr=0.99)     # try cmap='viridis' or cmap='gray'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB3BFjHPh7Uw"
   },
   "source": [
    "## Rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "k0g68cLfezI-"
   },
   "outputs": [],
   "source": [
    "# rejected components\n",
    "cnm.estimates.nb_view_components(img=cn_filter, idx=cnm.estimates.idx_components_bad,\n",
    "                                denoised_color='red', cmap='viridis',thr=0.9)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bqMG6wLZ5oz9"
   },
   "outputs": [],
   "source": [
    "pip install sciscripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bCXx1mSv5o0C"
   },
   "outputs": [],
   "source": [
    "SpatialFt=cnm.estimates.A\n",
    "import scipy.sparse\n",
    "nonzero_indices = scipy.sparse.find(SpatialFt)\n",
    "row, col, _ = nonzero_indices\n",
    "\n",
    "# Plot the locations of the neurons in the image\n",
    "plt.hexbin(row,col)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "7316fiXb5o0F"
   },
   "outputs": [],
   "source": [
    "print(SpatialFt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "F3PkhETA5o0H"
   },
   "outputs": [],
   "source": [
    "Yr1=np.reshape(images,((120, 756)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1CzCmq15o0I"
   },
   "outputs": [],
   "source": [
    "from caiman.utils import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9LeIu2Le5o0J"
   },
   "outputs": [],
   "source": [
    "print(np.shape(CellsCoordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "IlfUVHk05o0P"
   },
   "outputs": [],
   "source": [
    "print(CellsCoordinates[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wCpzDSG_5o0S"
   },
   "outputs": [],
   "source": [
    "print(len(CellsCoordinates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jui4xHlf5o0V"
   },
   "outputs": [],
   "source": [
    "print(len(idx0_coord[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDx4fRj15o0Y"
   },
   "outputs": [],
   "source": [
    "x = globals()[f'idx{259}_coord'][1,0]\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LFqo3hUOiuCY"
   },
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "cnm.estimates.detrend_df_f(detrend_only=True,frames_window=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNimZQY8jDZA"
   },
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-SemLe15o0f"
   },
   "outputs": [],
   "source": [
    "print(path_to_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iqc6XkxzjLvp"
   },
   "source": [
    "# Save the results in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-RJ0yknjDim"
   },
   "outputs": [],
   "source": [
    "#savec=path_to_results + 'analysis_results.csv'\n",
    "#print(savec)\n",
    "if save_hdf5:\n",
    "    cnm.save('analysis_results_pre.hdf5')\n",
    "    print('analysis_results_pre.hdf5 saved')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02TJD50Hjd8b"
   },
   "source": [
    "# Save the results in Matlab format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNmMwgOwjDmx"
   },
   "outputs": [],
   "source": [
    "if save_mat:\n",
    "    from scipy.io import savemat\n",
    "\n",
    "    results_dict = {\n",
    "                    'dirName': path_to_analyze,\n",
    "                    'numFiles': len(msFileList),\n",
    "                    'framesNum': len(RawTraces[1]),\n",
    "                    'maxFramesPerFile': 1000,\n",
    "                    'height': dims[0],\n",
    "                    'width': dims[1],\n",
    "    #                'Experiment': experimentName,\n",
    "     #               'ExperimentTimestamp': experiment_timestamp,\n",
    "                    'camNumber': 0,\n",
    "     #               'time': mstime,\n",
    "    #                'analysis_time': analysis_time,\n",
    "                    'ds': spatial_downsample_ratio,\n",
    "    #                'shifts': mc.shifts_rig,\n",
    "                    'meanFrame': [], #TO DO\n",
    "                    'Centroids': [], #TO DO\n",
    "                    'CorrProj': cn_filter,\n",
    "                    'PeakToNoiseProj': pnr,\n",
    "                    'FiltTraces': [], #TO DO\n",
    "                    'RawTraces': RawTraces.conj().transpose(), #swap time x neurons dimensions\n",
    "                    'SFP': SFP,\n",
    "                    'DeconvTraces':DeconvTraces,\n",
    "                    'numNeurons': SFP_dims[2],\n",
    "    #                'analysis_duration': analysis_duration\n",
    "                    }\n",
    "\n",
    "    SFPperm = np.transpose(SFP,[2,0,1])\n",
    "    savemat(path_to_results + 'SFP.mat', {'SFP': SFPperm})\n",
    "    savemat(path_to_results + 'ms.mat', {'ms': results_dict})\n",
    "    print('SFP.mat saved')\n",
    "    print('ms.mat  saved')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TrynbYTd5o05"
   },
   "source": [
    "# Checking if the Cell are the same in different Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ru11rjDjVafi"
   },
   "outputs": [],
   "source": [
    "f,axarr = plt.subplots(1, 2,figsize=(20,10))\n",
    "#plt.imsave(Dirpaht+'/PnrResult.jpg')\n",
    "img1=plt.imread('C:/Users/IC/Documents/PythonCampScript/pretraumaResults/prePnrResult.jpg')\n",
    "img2=plt.imread('C:/Users/IC/Documents/PythonCampScript/postraumaResults/posPnrResult.jpg')\n",
    "axarr[0].imshow(img1)\n",
    "axarr[1].imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYxDMcSr5o1A"
   },
   "outputs": [],
   "source": [
    "print('Good Neurons Index: \\n',idx_good)#cnm.estimates.idx_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "EyRqsZSo5o1F"
   },
   "outputs": [],
   "source": [
    "nome_do_arquivo_hdf5 = r'C:/Users/IC\\Documents/PythonCampScript/postraumaResults/analysis_results1.hdf5'\n",
    "with h5py.File(nome_do_arquivo_hdf5, \"r\") as f:\n",
    "    # List all groups\n",
    "    print(\"Keys: %s\" % f.keys())\n",
    "    a_group_key = list(f.keys())[0]\n",
    "\n",
    "    #     # Get the data\n",
    "    data = list(f[a_group_key])\n",
    "    display(data)\n",
    "    f=h5py.File(nome_do_arquivo_hdf5,'r')\n",
    "print(f['estimates'].keys())\n",
    "idx=(f['estimates']['S'][8])#get the deconv  S trace ALL\n",
    "#(f['estimates']['C'])#get the Raw trace ALL\n",
    "lp=f['estimates']['A']#get the Neuronposi trace ALL\n",
    "\n",
    "#xca=np.linspace(0,12,len(idx))\n",
    "#plt.plot(xca,lp)\n",
    "print(lp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "719xhmrR5o1H"
   },
   "outputs": [],
   "source": [
    "print(f['estimates'][])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_G0fu7gj5o1J"
   },
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyfyfkNc5o1K"
   },
   "outputs": [],
   "source": [
    "\n",
    "gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "print(np.shape(gray1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0gU18DJ5o1L"
   },
   "outputs": [],
   "source": [
    "lp=(cnm.estimates.A)\n",
    "print(np.shape(lp),'\\n',lp)\n",
    "Est=lp#cnm.estimates.A\n",
    "Dimensions = (np.shape(gray2))#images\n",
    "CenterOfMass = np.array([_['CoM'] for _ in visualization.get_contours(Est, Dimensions)])\n",
    "CellsCoordinates = [_['coordinates'] for _ in visualization.get_contours(Est, Dimensions)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OunAUo5Q5o1N"
   },
   "outputs": [],
   "source": [
    "for index in range(len(cnm.estimates.C)):#cnm.estimates.C\n",
    "    globals()[f'idx{index}_coord'] = CellsCoordinates[index]\n",
    "idx0_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "evIsK8NX5o1P"
   },
   "outputs": [],
   "source": [
    "#lo=int(input('Index a se analizar: '))\n",
    "\n",
    "#fig,ax = plt.subplots(1,2,figsize=(20,9))\n",
    "\n",
    "#ax[1].set_xlim(0,1)\n",
    "for lo in cnm.estimates.idx_components[::10]:\n",
    "    for j in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        x = globals()[f'idx{lo}_coord'][j,0]\n",
    "        y = globals()[f'idx{lo}_coord'][j,1]\n",
    "        plt.scatter(x = x,y=y,s= 0.8, c='r')\n",
    "        plt.scatter(cluster1_centers[:, 0], cluster1_centers[:, 1],alpha = 0.4 )\n",
    "        plt.imshow(threshold2)\n",
    "        plt.title(f'Neuron Index:{lo}')\n",
    "    plt.show()\n",
    "    plt.plot(np.linspace(0,2,11000),cnm.estimates.C[lo],linewidth=0.8)\n",
    "    plt.title(f'Raw trace Index:{lo}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23SS6Dz95o1R"
   },
   "outputs": [],
   "source": [
    "plt.imshow(gray2)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "optvpw0C5o1T"
   },
   "outputs": [],
   "source": [
    "#fig, axs = plt.subplots(5, 2, figsize=(20, 10), constrained_layout=True)\n",
    "for index in cnm.estimates.idx_components[0:200:5] :\n",
    "    for j in range(len(globals()[f'idx{index}_coord'][:,0])):\n",
    "        x = globals()[f'idx{index}_coord'][j,0]\n",
    "        y = globals()[f'idx{index}_coord'][j,1]\n",
    "        plt.scatter(x = x,y=y,s= 0.8, c='r')\n",
    "        plt.imshow(gray1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgwPmd765o1W"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "imgc2=gray2[::,55:295:]\n",
    "imgc1=gray1[::,55:295:]\n",
    "#gray2=gray2[::,25:335:]\n",
    "#gray1=gray1[::,20:330:]\n",
    "print(np.shape(imgc1))\n",
    "#    if i >=110\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(imgc1)\n",
    "ax[1].imshow(imgc2)\n",
    "#ax.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y20FyQB45o1Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfJlZFXv5o1Z"
   },
   "outputs": [],
   "source": [
    "_, threshold1 = cv2.threshold(gray1,98, 255, cv2.THRESH_BINARY)\n",
    "_, threshold2 = cv2.threshold(gray2,90, 255, cv2.THRESH_BINARY)\n",
    "f,axrr=plt.subplots(1, 2,figsize=(20,10))\n",
    "axrr[0].imshow(threshold1)\n",
    "axrr[0].set_title('PreTrauma')\n",
    "axrr[1].imshow(threshold2)\n",
    "axrr[1].set_title('PosTrauma')\n",
    "#plt.savefig(\"C:/Users/IC/Documents/PythonCampScript/postraumaResults.svg\",format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vcVNlOe5o1Z"
   },
   "source": [
    "# check the neuro and his index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6A8LL1F5o1a"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "# Definir o n√∫mero de neur√¥nios\n",
    "NUM_NEURONS = 90\n",
    "\n",
    "# Detectar bordas usando Canny\n",
    "edges1 = cv2.Canny(threshold1, 100, 200)\n",
    "edges2 = cv2.Canny(threshold2, 100, 200)\n",
    "#\n",
    "\n",
    "\n",
    "# Encontrar os contornos das bordas\n",
    "contours1, hierarchy1 = cv2.findContours(edges1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours2, hierarchy2 = cv2.findContours(edges2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Fazer o clustering usando KMeans\n",
    "cluster1 = KMeans(n_clusters=NUM_NEURONS, random_state=None ).fit(np.array([cnt[0][0] for cnt in contours1]))\n",
    "cluster2 = KMeans(n_clusters=NUM_NEURONS, random_state=None).fit(np.array([cnt[0][0] for cnt in contours2]))\n",
    "\n",
    "NeuronsFound1=(len(cluster1.labels_))\n",
    "NeuronsFound2=(len(cluster2.labels_))\n",
    "# Criar um dicion√°rio onde cada chave √© um neur√¥nio e cada valor √© um √≠ndice √∫nico\n",
    "#neurons = {}\n",
    "#for i in range(NUM_NEURONS):\n",
    "    #neurons[i] = (cluster1.labels_ == i).astype(int) + (cluster2.labels_ == i).astype(int)\n",
    "# Exibir o dicion√°rio\n",
    "#print(neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tysV23vA5o1e"
   },
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the cluster centers\n",
    "cluster1_centers = cluster1.cluster_centers_\n",
    "cluster2_centers = cluster2.cluster_centers_\n",
    "\n",
    "# Plot the results using scatter plot\n",
    "f,axrrr=plt.subplots(1, 2,figsize=(10,5))\n",
    "axrrr[0].scatter(cluster1_centers[:, 0], cluster1_centers[:, 1], c='red',alpha = 0.4)\n",
    "\n",
    "axrrr[1].scatter(cluster2_centers[:, 0], cluster2_centers[:, 1], c='blue',alpha = 0.4)\n",
    "\n",
    "# Add title and labels to the plot\n",
    "#plt.xlabel(\"X\")\n",
    "#plt.ylabel(\"Y\")\n",
    "\n",
    "# Show the plot\n",
    "axrrr[0].imshow(threshold1)\n",
    "axrrr[1].imshow(threshold2)\n",
    "axrrr[0].set_title('Pretrauma = Cluster X Image ')\n",
    "#axrrr[0].legend(str(136))\n",
    "axrrr[1].set_title('Postrauma = Cluster X Image ')\n",
    "#axrrr[1].legend(str(154))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mWOQZFUv5o1g"
   },
   "outputs": [],
   "source": [
    "plt.imshow(edges1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67X4ki9o5o1i"
   },
   "outputs": [],
   "source": [
    "#print(len(cluster2_centers[:,0]))\n",
    "clidx=np.array([])\n",
    "xlop=np.array([])\n",
    "for i in range(len(cluster2_centers[:,0])):\n",
    "    if (cluster1_centers[i,0]> 50) and (cluster1_centers[i,0]< 320) and (cluster2_centers[i,0]> 50) and (cluster2_centers[i,0]< 320):\n",
    "        for j in range(len(cluster2_centers[:,0])):\n",
    "                if ((cluster2_centers[j,0]-cluster1_centers[i,0])<12)  and ((cluster2_centers[j,1]-cluster1_centers[i,1])<12)and ((cluster2_centers[j,0]-cluster1_centers[i,0])>5)  and ((cluster2_centers[j,1]-cluster1_centers[i,1])>0):\n",
    "                    clidx=np.append(clidx,j)\n",
    "                    xlop=np.append(xlop,i)\n",
    "print(clidx,'\\n',xlop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "xpDgTWiJ5o1v"
   },
   "outputs": [],
   "source": [
    "for i in range(len(cluster2_centers[:,0])):\n",
    "    if (cluster1_centers[i,0]> 50) and (cluster1_centers[i,0]< 320) and (cluster2_centers[i,0]> 50) and (cluster2_centers[i,0]< 320):\n",
    "        for j in range(len(cluster2_centers[:,0])):\n",
    "                if ((cluster2_centers[j,0]-cluster1_centers[i,0])<12)  and ((cluster2_centers[j,1]-cluster1_centers[i,1])<12)and ((cluster2_centers[j,0]-cluster1_centers[i,0])>0)  and ((cluster2_centers[j,1]-cluster1_centers[i,1])>0):\n",
    "                    print(\"x:\",cluster2_centers[j,0]-cluster1_centers[i,0]  ,\"\\n y: \", (cluster2_centers[j,1]-cluster1_centers[i,1]),\"\\n x: \", (cluster2_centers[j,0]-cluster1_centers[i,0]) ,\"\\n y:\", cluster2_centers[j,1]-cluster1_centers[i,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WHyhzu05o1x"
   },
   "outputs": [],
   "source": [
    "for i in xlop:\n",
    "    i=int(i)\n",
    "    for j in clidx:\n",
    "        j=int(j)\n",
    "        plt.scatter(cluster1_centers[i,0],cluster1_centers[i,1],c='r')\n",
    "        plt.scatter(cluster2_centers[j,0],cluster2_centers[j,1],c='g')\n",
    "        plt.imshow(gray1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "foYO5KSQ5o1z"
   },
   "outputs": [],
   "source": [
    "#[39. 42. 52. 36. 78. 50.  2.]\n",
    "# [10. 28. 33. 54. 61. 63. 85.]\n",
    "pog=2\n",
    "champ=10\n",
    "plt.scatter(cluster1_centers[pog,0],cluster1_centers[pog,1],c='r')\n",
    "plt.scatter(cluster2_centers[champ,0],cluster2_centers[champ,1],c='g')\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYDcY18j5o12"
   },
   "outputs": [],
   "source": [
    "totalv=(len(cluster1_centers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JRRMmQts5o16"
   },
   "outputs": [],
   "source": [
    "cont=0\n",
    "for i in range(len(cluster1_centers)):\n",
    "    if (cluster1_centers[i,0]> 50) and (cluster1_centers[i,0]< 320):\n",
    "        plt.scatter(cluster1_centers[i,0],cluster1_centers[i,1],c='r')\n",
    "        plt.imshow(img1)\n",
    "        plt.title(f'img {i}')\n",
    "        cont+=1\n",
    "        plt.show()\n",
    "print(totalv-cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBF989nB5o19"
   },
   "outputs": [],
   "source": [
    "from sciscripts.Analysis.Analysis import PolygonArea\n",
    "CellsArea = np.array([PolygonArea(_[:], _[:]) for _ in globals()[f'idx{259}_coord']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmMefTND5o2A"
   },
   "outputs": [],
   "source": [
    "CellsArea = np.array([PolygonArea(_[:], _[:]) for _ in globals()[f'idx{13}_coord']])\n",
    "print((CellsArea))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dDQ662T5o2B"
   },
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "bestlab1=np.array([])\n",
    "bestlab2=np.array([])\n",
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "#Define the data points\n",
    "\n",
    "#Create the clustering model\n",
    "clustering = SpectralClustering(n_clusters=10, affinity='nearest_neighbors', assign_labels='discretize')\n",
    "\n",
    "#Fit the model to the data\n",
    "clustering.fit(np.concatenate((threshold1, threshold2)))\n",
    "\n",
    "#Check if the two neurons are the same\n",
    "print(len(clustering.labels_[:]))\n",
    "for i in range(len(clustering.labels_[:])):\n",
    "    for j in range(len(clustering.labels_[:])):\n",
    "        if clustering.labels_[i] == clustering.labels_[j]:\n",
    "            #print('The two neurons are the same.')\n",
    "            bestlab1=np.append(bestlab1,clustering.labels_[i])\n",
    "            bestlab2=np.append(bestlab2,clustering.labels_[j])\n",
    "        #else:\n",
    "            #print('The two neurons are different.')\n",
    "print(bestlab1,'\\n',bestlab2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-S6NXWmw5o2B"
   },
   "outputs": [],
   "source": [
    "_, threshold1 = cv2.threshold(gray1, 80, 255, cv2.THRESH_BINARY)\n",
    "_, threshold2 = cv2.threshold(gray2, 80, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Find the contours in each image\n",
    "contours1, _ = cv2.findContours(threshold1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours2, _ = cv2.findContours(threshold2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Select the largest contour in each image\n",
    "neuron1 = max(contours1, key=cv2.contourArea)\n",
    "neuron2 = max(contours2, key=cv2.contourArea)\n",
    "\n",
    "# Find the centroid of each neuron\n",
    "M1 = cv2.moments(neuron1)\n",
    "cx1 = int(M1['m10'] / M1['m00'])\n",
    "cy1 = int(M1['m01'] / M1['m00'])\n",
    "\n",
    "M2 = cv2.moments(neuron2)\n",
    "cx2 = int(M2['m10'] / M2['m00'])\n",
    "cy2 = int(M2['m01'] / M2['m00'])\n",
    "\n",
    "# Overlay the two images\n",
    "vis = np.concatenate((gray1, gray2), axis=1)\n",
    "\n",
    "# Draw a line between the centroids of the neurons\n",
    "cv2.line(vis, (cx1, cy1), (cx2 + gray1.shape[1], cy2), (0, 0, 255), 2)\n",
    "\n",
    "# Show the overlayed image\n",
    "cv2.imshow(\"Neurons\", vis)\n",
    "cv2.waitKey()\n",
    "\n",
    "print(cx1,cy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9mFkQKR5o2C"
   },
   "outputs": [],
   "source": [
    "edges1 = cv2.Canny(imgc1, 100, 200)\n",
    "edges2 = cv2.Canny(imgc2, 100, 200)\n",
    "f,ax=plt.subplots(1,2)\n",
    "\n",
    "ax[0].imshow(edges1)\n",
    "ax[1].imshow(edges2)\n",
    "#contours2, hierarchy2 = cv2.findContours(edges1[40:], cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#print(contours2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6Cc5pZu5o2E"
   },
   "outputs": [],
   "source": [
    "print((imgc2.max()))#()-(imgc2.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tq5b--b15o2G"
   },
   "outputs": [],
   "source": [
    "#print(np.shape(contours1[81]))\n",
    "cimgc1=imgc1.copy()\n",
    "cimgc1=cv2.drawContours(image=cimgc1, contours=contours1, contourIdx=-1, color=(0, 255, 255), thickness=1)\n",
    "\n",
    "#print(contours1[0][0][0])\n",
    "#plt.scatter(contours1[:][:][:][0],contours1[:][:][:][1])\n",
    "f,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "\n",
    "ax[0].imshow(imgc1)\n",
    "ax[1].imshow(cimgc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "uGF4kmYM5o2J"
   },
   "outputs": [],
   "source": [
    "data=np.concatenate(((threshold1, threshold2)))\n",
    "# Define the number of clusters\n",
    "n_clusters = 20\n",
    "\n",
    "# Create the clustering model\n",
    "clustering = SpectralClustering(n_clusters=n_clusters, affinity='rbf', assign_labels='kmeans')\n",
    "\n",
    "# Fit the model to the data\n",
    "clustering.fit(data)\n",
    "\n",
    "# Plot the clustering results\n",
    "fig, ax = plt.subplots()\n",
    "for i in range(n_clusters):\n",
    "    cluster = data[clustering.labels_ == i]\n",
    "    #ax.set_xlim(0,80)\n",
    "    #ax.set_ylim(0,80)\n",
    "    ax.scatter(cluster[:, 0], cluster[:, 1], s=10, label=f'Cluster {i}')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PbI6gyA5o2P"
   },
   "outputs": [],
   "source": [
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "weI_eqMR5o2S"
   },
   "outputs": [],
   "source": [
    "File = r'C:/Users/IC/Documents/PythonCampScript/postraumaResults/analysis_results.hdf5'\n",
    "F = h5py.File(File, 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CtZ9b-jY5o2T"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "xwXcGvu35o2U"
   },
   "outputs": [],
   "source": [
    "Dav=(Tesl['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-I8lmt45o2a"
   },
   "outputs": [],
   "source": [
    "Raw\n",
    "for i in range(len(Dav)):\n",
    "    d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNdJSNmz5o2c"
   },
   "outputs": [],
   "source": [
    "Tesl=(F['estimates']['C'])\n",
    "Est=Tesl=(F['estimates']['A']['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCnyBJzY5o2e"
   },
   "source": [
    "# Post Trauma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLotXd8r5o2f"
   },
   "source": [
    "## Copy miniscope videos for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMrHPDyi5o2f"
   },
   "outputs": [],
   "source": [
    "adjust=False\n",
    "path_to_analyze1='C:/Users/IC/Documents/PythonCampScript/postrauma'\n",
    "path_to_results1='C:/Users/IC/Documents/PythonCampScript/postraumaResults'\n",
    "\n",
    "sessionFilesResponse1 = os.listdir(path_to_analyze1)\n",
    "filesList1 = []\n",
    "msFileList1 = []\n",
    "datFileList1 = []\n",
    "\n",
    "for file in sessionFilesResponse1:\n",
    "    filesList1.append(file)\n",
    "\n",
    "\n",
    "for i in filesList1[:]:\n",
    "    if i.startswith('ms') and i.endswith('.avi'):\n",
    "        msFileList1.append(i)\n",
    "    if i.endswith('.dat'):\n",
    "        datFileList1.append(i)\n",
    "\n",
    "msFileList1 = sorted(msFileList1, key=lambda x: int(re.sub('[msCam.avi]','', x)))\n",
    "\n",
    "if adjust:\n",
    "    msFileList1 = msFileList1[0:20]\n",
    "\n",
    "print('Miniscope files in folder:')\n",
    "print(msFileList1)\n",
    "msLocalFileList1 = [path_to_results1 + s for s in msFileList1]\n",
    "\n",
    "if len(msFileList1) == 0:\n",
    "    print(\"No miniscope avi files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ekcqiyrz5o2j"
   },
   "outputs": [],
   "source": [
    "\n",
    "for fname in msFileList1:\n",
    "    src = os.path.join(path_to_analyze1, fname)\n",
    "    dst = os.path.join(path_to_results1, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "for fname in datFileList1:\n",
    "    src = os.path.join(path_to_analyze1, fname)\n",
    "    dst = os.path.join(path_to_results1, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    print('file ' + fname + ' copyed for analysis')\n",
    "\n",
    "# Create a list of files downloaded on the virtual machine\n",
    "msLocalFileList = [path_to_results1 + s for s in msFileList1]\n",
    "fnames1 = msLocalFileList1\n",
    "\n",
    "print('Files copyed for analysis:')\n",
    "print(msFileList1)\n",
    "print(datFileList1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNeGEJXr5o2k"
   },
   "source": [
    "## Loading the mmap file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d19CmDKE5o2l"
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "frate = frame_rate*temporal_downsample_ratio                       # movie frame rate\n",
    "decay_time = decay_time                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (6, 6)      # maximum allowed rigid shift\n",
    "strides = (48, 48)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)      # overlap between patches (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "use_cuda = True         # Set to True in order to use GPU\n",
    "only_init_patch = False\n",
    "memory_fact = 0.8\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'niter_rig': 1,\n",
    "    'splits_rig': 20,  # for parallelization split the movies in  num_splits chuncks across time\n",
    "    # if none all the splits are processed and the movie is saved\n",
    "    'num_splits_to_process_rig': None, # intervals at which patches are laid out for motion correction\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan,\n",
    "    'use_cuda' : use_cuda,\n",
    "    'only_init_patch' : only_init_patch,\n",
    "    'memory_fact': memory_fact\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1ZQJqKj5o2o",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)\n",
    "\n",
    "sessionFilesResponse1 = os.listdir(r'C:/Users/IC/Documents/PythonCampScript/postraumaResults')\n",
    "Dirpaht1= r'C:/Users/IC/Documents/PythonCampScript/postraumaResults'\n",
    "\n",
    "filesList1 = []\n",
    "fname_new1 = []\n",
    "\n",
    "for file in sessionFilesResponse1:\n",
    "  filesList1.append(file)\n",
    "\n",
    "for i in filesList1[:]:\n",
    "  if i.startswith('memmap__'):\n",
    "    fname_new1=i\n",
    "\n",
    "fname_new1= Dirpaht1  + '/' + fname_new1\n",
    "print(fname_new1)\n",
    "\n",
    "bord_px=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uBkpQrUU5o2s"
   },
   "outputs": [],
   "source": [
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new1)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0_j45Z25o2w"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "%env HV_DOC_HTML=True\n",
    "# compute some summary images (correlation and peak to noise)\n",
    "\n",
    "gausean_width = 3.0     #gSig... specifies a gausean 2D width for approximating a neuron\n",
    "\n",
    "hv.extension('bokeh')\n",
    "downsample_factor=int(images[::].shape[0]/500)\n",
    "cn_filter1, pnr1 = cm.summary_images.correlation_pnr(images[::downsample_factor], gSig=gausean_width, swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "nb_inspect_correlation_pnr(cn_filter1, pnr1)\n",
    "show(hv.render(nb_inspect_correlation_pnr(cn_filter1, pnr1)))\n",
    "print(cn_filter1.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sJJUV0x95o20"
   },
   "outputs": [],
   "source": [
    "plt.imsave(path_to_results1+'/PnrResult.jpg',arr=pnr1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2LLWc365o22"
   },
   "source": [
    "## (step #4) --> Optimize the parameters \"min_corr and min_pnr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KY_xk7ED5o24"
   },
   "outputs": [],
   "source": [
    "# Now sert the parameters\n",
    "min_corr=0.6 # min correlation of peak (from correlation image)\n",
    "min_pnr =9 # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wkAwSIcA5o26"
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "# frate = 10 # movie frame rate\n",
    "decay_time = decay_time  # length of a typical transient in seconds\n",
    "fnames=fnames\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = gSig_filt    # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = max_shifts  # maximum allowed rigid shift\n",
    "strides = strides       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = overlaps      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = max_deviation_rigid  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdzamjEp5o28"
   },
   "source": [
    "## Parameter setting for CNMF-E\n",
    "We now define some parameters for the source extraction step using the CNMF-E algorithm.\n",
    "We construct a new dictionary and use this to modify the *existing* `params` object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ITXRoSCf5o2_"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# parameters for source extraction and deconvolution\n",
    "av_diameter=4*gausean_width+1\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None\n",
    "gSig = (gausean_width, gausean_width)       # gaussian width of a 2D gaussian kernel, which approximates a neuron\n",
    "gSiz = (av_diameter, av_diameter)     # average diameter of a neuron, in general 4*gSig+1\n",
    "Ain = None          # possibility to seed with predetermined binary masks\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb= 0: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb<-1: Don't return background\n",
    "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "#                     else it is set automatically\n",
    "min_corr = min_corr       # min peak value from correlation image\n",
    "min_pnr  = min_pnr       # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use 'corr_pnr' for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': bord_px})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skrjfGWn5o3D"
   },
   "source": [
    "# Perform CNMFe extraction\n",
    "This will take a while. Coffee time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6VgATu0X5o3H"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PdZJiyu65o3J"
   },
   "outputs": [],
   "source": [
    "#%%capture\n",
    "start = time.time()\n",
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "cnm.fit(images)\n",
    "end = time.time()\n",
    "TotalTime1=(end-start)/60\n",
    "\n",
    "\n",
    "print(f'CNMFe has been done in  {TotalTime1} seconds!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubsK0S9R5o3N"
   },
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier\n",
    "\n",
    "After setting some parameters we again modify the existing `params` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZLeKWCs5o3Q"
   },
   "source": [
    "## (step #6) --> Optimize the parameters min_SNR and r_values_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G00x26Nw5o3U"
   },
   "outputs": [],
   "source": [
    "ls /root/caiman_data/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jj-tRIPS5o3X"
   },
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 3.0            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.80   # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worst quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnm.estimates.evaluate_components(images, cnm.params, dview=dview)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WhpCXIeu5o3c"
   },
   "outputs": [],
   "source": [
    "#gray1 = cv2.cvtColor(pnr, cv2.COLOR_BGR2GRAY)\n",
    "_, threshold11 = cv2.threshold(pnr1, 9, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "plt.imshow(threshold11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rivfhHZs5o3f"
   },
   "outputs": [],
   "source": [
    "print(path_to_results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VGkk1war5o3k"
   },
   "outputs": [],
   "source": [
    "savehd=('analysis_results_pos.hdf5')\n",
    "if save_hdf5:\n",
    "    cnm.save(savehd)\n",
    "    print(savehd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F82_aHgj5o3q"
   },
   "outputs": [],
   "source": [
    "Est1=cnm.estimates.A\n",
    "PosRawTraces=cnm.estimates.C\n",
    "Dimensions1 = (np.shape(gray1))#images\n",
    "CenterOfMass = np.array([_['CoM'] for _ in visualization.get_contours(Est1, Dimensions1)])\n",
    "CellsCoordinates = [_['coordinates'] for _ in visualization.get_contours(Est1, Dimensions1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dR_oHdB35o3r"
   },
   "outputs": [],
   "source": [
    "for index in range(len(cnm.estimates.C)):#cnm.estimates.C\n",
    "    globals()[f'idx{index}_coord1'] = CellsCoordinates[index]\n",
    "idx0_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3OYPw5-5o3v"
   },
   "outputs": [],
   "source": [
    "#lo=int(input('Index a se analizar: '))\n",
    "\n",
    "#fig,ax = plt.subplots(1,2,figsize=(20,9))\n",
    "\n",
    "#ax[1].set_xlim(0,1)\n",
    "for lo in cnm.estimates.idx_components[::10]:\n",
    "    for j in range(len(globals()[f'idx{lo}_coord1'][:,0])):\n",
    "        x1 = globals()[f'idx{lo}_coord1'][j,0]\n",
    "        y1 = globals()[f'idx{lo}_coord1'][j,1]\n",
    "        plt.scatter(x = x1,y=y1,s= 0.8, c='r')\n",
    "        if (-10)<=x1-cluster2_centers[j,0]<=10 and (-10)<=y1-cluster2_centers[j,1]<=10:\n",
    "            plt.scatter(cluster2_centers[j, 0], cluster2_centers[j, 1],alpha = 0.4,c='y' )\n",
    "        plt.imshow(threshold2)\n",
    "        plt.title(f'Neuron Index:{lo}')\n",
    "\n",
    "    plt.show()\n",
    "    plt.plot(np.linspace(0,2,11000-1),cnm.estimates.C[lo],linewidth=0.8)\n",
    "    plt.title(f'Raw trace Index:{lo}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlFuIZ9D5o31"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uCBzbwPg5o33"
   },
   "outputs": [],
   "source": [
    "print(len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fUzgajqv5o35"
   },
   "outputs": [],
   "source": [
    "#lo=int(input('Index a se analizar: '))\n",
    "\n",
    "#fig,ax = plt.subplots(1,2,figsize=(20,9))\n",
    "\n",
    "#ax[1].set_xlim(0,1)\n",
    "for lo in cnm.estimates.idx_components[::5]:\n",
    "    for j in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        if globals()[f'idx{lo}_coord1'][j,0]>50 and globals()[f'idx{lo}_coord1'][j,0]<310:\n",
    "            x1 = globals()[f'idx{lo}_coord1'][j,0]\n",
    "            y1 = globals()[f'idx{lo}_coord1'][j,1]\n",
    "\n",
    "    for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        if globals()[f'idx{lo}_coord'][j,0]>50 and globals()[f'idx{lo}_coord'][j,0]<310:\n",
    "            x = globals()[f'idx{lo}_coord'][k,0]\n",
    "            y = globals()[f'idx{lo}_coord'][k,1]\n",
    "    plt.scatter(x = x1,y=y1,s= 0.8, c='r')\n",
    "    plt.scatter(x=x, y=y,s = 0.8, c= 'g' )\n",
    "    plt.imshow(threshold2)\n",
    "    plt.title(f'Neuron Index:{lo}')\n",
    "    plt.show()\n",
    "    #plt.plot(np.linspace(0,2,11000-1),cnm.estimates.C[lo],linewidth=0.8)\n",
    "    plt.title(f'Raw trace Index:{lo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bum8zTsw5o38"
   },
   "outputs": [],
   "source": [
    "#lo=int(input('Index a se analizar: '))\n",
    "\n",
    "#fig,ax = plt.subplots(1,2,figsize=(20,9))\n",
    "\n",
    "#ax[1].set_xlim(0,1)\n",
    "for lo in nwidxg[:]:\n",
    "    lo=int(lo)\n",
    "    for j in range(len(globals()[f'idx{lo}_coord1'][:,0])):\n",
    "        x1 = globals()[f'idx{lo}_coord1'][j,0]\n",
    "        y1 = globals()[f'idx{lo}_coord1'][j,1]\n",
    "        plt.scatter(x = x1,y=y1,s= 0.8, c='r')\n",
    "    for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        x = globals()[f'idx{lo}_coord'][k,0]\n",
    "        y = globals()[f'idx{lo}_coord'][k,1]\n",
    "        plt.scatter(x=x, y=y,s = 0.8, c= 'g' )\n",
    "        plt.imshow(pnr1)\n",
    "        plt.title(f'Neuron Index:{lo}')\n",
    "    plt.show()\n",
    "#plt.plot(np.linspace(0,2,11000-1),cnm.estimates.C[lo],linewidth=0.8)\n",
    "#plt.title(f'Raw trace Index:{lo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7YSkccPU5o4A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RdGJ0Rdb5o4C"
   },
   "outputs": [],
   "source": [
    "nwidxg=np.array([])\n",
    "for i in cnm.estimates.idx_components:\n",
    "        for j in range(len(idx_good)):\n",
    "            if i==idx_good[j]:\n",
    "                nwidxg=np.append(nwidxg,int(i))\n",
    "print ((nwidxg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBFn9hvO5o4E"
   },
   "outputs": [],
   "source": [
    "len(globals()[f'idx{lo}_coord1'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_YAv-mCa5o4G"
   },
   "outputs": [],
   "source": [
    "difx=np.array([])\n",
    "dify=np.array([])\n",
    "for lo in nwidxg[:]:\n",
    "    lo=int(lo)\n",
    "    for j in range(len(globals()[f'idx{lo}_coord1'][:,0])):\n",
    "            x1 = globals()[f'idx{lo}_coord1'][j,0]\n",
    "            y1 = globals()[f'idx{lo}_coord1'][j,1]\n",
    "            for k in (range(len(globals()[f'idx{lo}_coord'][:,0]))):\n",
    "                x = globals()[f'idx{lo}_coord'][k,0]\n",
    "                y = globals()[f'idx{lo}_coord'][k,1]\n",
    "                difx=np.append(difx,x1[j]-x[k])\n",
    "                dify=np.append(dify,y1-y)\n",
    "print(difx,\"\\n\",dify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xF-sY9h5o4I"
   },
   "outputs": [],
   "source": [
    "x1=np.array([])\n",
    "for i in nwidxg[:]:\n",
    "    for i in range(len(globals()[f'idx{lo}_coord1'][:,0])):\n",
    "        x1=np.append(x1,globals()[f'idx{lo}_coord1'][i,0])\n",
    "print(len(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peOUCeA95o4J"
   },
   "outputs": [],
   "source": [
    "pidx_good=cnm.estimates.idx_components\n",
    "print('Good idx: ', idx_good,'\\n','Components: ',cnm.estimates.idx_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HLSnFCK5o4L"
   },
   "outputs": [],
   "source": [
    "#preEst\n",
    "#posEst1\n",
    "\n",
    "newa=np.vstack((Est,Est1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EH9Ad6fs5o4N"
   },
   "outputs": [],
   "source": [
    "Data=np.asarray(newa)\n",
    "np.save(\"Positions.npy\",Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0aDQBg1f5o4S"
   },
   "outputs": [],
   "source": [
    "dataout=np.load(\"Positions.npy\",allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "6ys-dK1n5o4V"
   },
   "outputs": [],
   "source": [
    "print(dataout[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TmtY6jQD5o4X"
   },
   "outputs": [],
   "source": [
    "pst=[23 , 24,  25 , 27,  28,  30,  31,  35,  36,  38,  39,  41 , 42,  43,  44,  46,  47,  48,\n",
    "  49,  51,  53 , 57,  59,  60,  62,  63,  64,  65,  66,  67,  69 , 70,  71,  72,  73,  74,\n",
    "  76,  77,  78,  79,  86,  88,  91,  93,  94,  97,  99, 108, 109, 111, 112, 113, 115, 116]\n",
    "pt=[24  ,25 , 26 , 27 , 28 , 33 , 34 , 36 , 39 , 40,  45,  46 , 47 , 48 , 49 , 50 , 51 , 52,\n",
    "  53  ,55 , 56 , 57 , 58 , 61  ,62 , 63 , 64 , 69,  70,  73,  79,  80 , 81 , 82 , 83 , 84,\n",
    "  90 , 91 , 92  ,94  ,95  ,96  ,97  ,98, 100, 102, 103 ,104 ,108 ,110 ,112, 114, 124, 125]\n",
    "x=np.array([])\n",
    "x1=np.array([])\n",
    "y=np.array([])\n",
    "y1=np.array([])\n",
    "lo=54\n",
    "#clnpst=np.array([])\n",
    "cln=np.array([])\n",
    "for l in range(200):\n",
    "    i=int(pidx_good[l])\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "        x1 = np.append(x1,globals()[f'idx{i}_coord1'][j,0])\n",
    "        y1 = np.append(y1,globals()[f'idx{i}_coord1'][j,1])\n",
    "    lo=idx_good[l]\n",
    "    for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        x = np.append(x,globals()[f'idx{lo}_coord'][k,0])\n",
    "        y = np.append(y,globals()[f'idx{lo}_coord'][k,1])\n",
    "\n",
    "    plt.scatter(x=x, y=y,s = 0.8, c= 'r' )\n",
    "    plt.scatter(x = x1,y=y1,s= 0.8, c='g')\n",
    "    plt.imshow(img1)\n",
    "    plt.title(f'NeuronPST Index:{i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "bedZmt-S5o4Z"
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    k=pidx_good[i]\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PegiTEJB5o4a"
   },
   "outputs": [],
   "source": [
    "print(len(pidx_good))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hi7dexQ5o4b"
   },
   "outputs": [],
   "source": [
    "idxa=np.array([])\n",
    "for i in range(len(x)):\n",
    "    if (x1[i]-x[i])>0 and (x1[i]-x[i])<5 and (y1[i]-y[i])>0 and (y1[i]-y[i])<5:\n",
    "        #print((x1[i]-x[i]))\n",
    "        #print((y1[i]-y[i]))\n",
    "        #print(i)\n",
    "        idxa=np.append(idxa,i)\n",
    "print(idxa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cpdUN6yt5o4e"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x1,y1,s=0.8,c='g')\n",
    "plt.scatter(x,y,s=0.8,c='r')\n",
    "plt.imshow(pnr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LZs68Vf75o4s"
   },
   "outputs": [],
   "source": [
    "lo=[  0   ,1   ,2 ,  3  , 4   ,5   ,6   ,7   ,8   ,9  ,10  ,11  ,12 , 18  ,28  ,31  ,33  ,34\n",
    "  ,35  ,36  ,37  ,38  ,42  ,43  ,44  ,47  ,49  ,53  ,54  ,58  ,59  ,61  ,62  ,63  ,64  ,65\n",
    "  ,66 , 67,  68  ,69  ,70  ,71  ,72  ,73  ,74  ,75  ,76 , 77  ,78  ,79  ,83  ,85  ,86  ,87\n",
    "  ,88  ,89, 102, 103, 104, 105, 106 ,107 ,108, 109, 110 ,111, 113, 114, 115 ,116 ,117 ,118\n",
    " ,119 ,120 ,121 ,122, 123 ,127 ,130 ,131 ,132, 136, 139, 141, 144 ,145, 146, 147 ,149 ,150\n",
    " ,151 ,153 ,154, 155, 156, 157, 159, 160, 161, 162, 164, 165 ,166, 173 ,177, 180, 183, 188\n",
    " ,189, 191, 192 ,193 ,196 ,197 ,198 ,199 ,200 ,201 ,204 ,205, 206, 207 ,208 ,209 ,210 ,211\n",
    " ,212, 213 ,214, 215, 216 ,217, 219, 220, 221, 222 ,223, 224, 225, 226 ,227, 228 ,229 ,231\n",
    " ,234 ,235 ,236, 237, 238, 239 ,240 ,241 ,242, 243, 245, 247, 248, 249, 250, 262, 264, 266\n",
    " ,267 ,270, 272, 273 ,276, 277, 278 ,279, 280 ,281 ,283 ,284 ,285 ,287 ,288 ,289 ,290 ,291\n",
    " ,292 ,293 ,294, 295, 296 ,297, 298, 299, 300 ,301 ,302 ,303 ,304 ,305 ,307, 308 ,309 ,310\n",
    " ,311 ,313, 314, 315, 317, 329, 330 ,331, 333, 334, 335, 339 ,340, 342, 343, 344, 345 ,346\n",
    " ,347, 348 ,349 ,350 ,351 ,352 ,353 ,354, 355, 356 ,358 ,359 ,360 ,361 ,362 ,363 ,364 ,365,\n",
    " 366, 368, 376, 377, 378, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392,\n",
    " 393, 395, 396, 398, 399, 401, 403, 404, 411, 412, 413, 414, 415, 416, 419, 420 ,421, 423,\n",
    " 424, 425, 426, 428, 429, 432, 434, 436, 437, 438 ,439 ,440 ,441, 442, 443, 444 ,445, 446,\n",
    " 449 ,450 ,451 ,452, 453 ,454 ,455 ,456 ,457 ,458 ,459 ,460 ,461 ,462, 463 ,464 ,465, 466,\n",
    " 467 ,468, 469, 470 ,471 ,472, 473, 474 ,475 ,476 ,477 ,478 ,479 ,480 ,481 ,485 ,487]#idx_good\n",
    "io=[  0  , 1,  16,  18,  19,  20,  21,  24,  27  ,29  ,30,  31,  32,  33,  34,  35,  36,  37\n",
    " , 40 , 42  ,43  ,44,  45,  47,  48,  49,  50,  51,  52  ,54  ,55,  56,  58,  59,  60,  61\n",
    " , 63  ,67  ,78  ,79,  81,  82,  83,  84,  85,  87,  88  ,89  ,90,  91 , 92,  93,  94,  95\n",
    " , 96  ,97  ,98  ,99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 122, 124\n",
    " ,126 ,127 ,130 ,131, 132, 133, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 146, 147\n",
    " ,148 ,149 ,150 ,151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165\n",
    " ,166, 167 ,168 ,169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 187\n",
    " ,189, 191 ,196 ,198, 199, 200, 201, 202, 203, 204, 205 ,206, 207, 208, 209, 210, 211, 212\n",
    " ,213, 214 ,215 ,216, 217, 218, 219, 220, 221, 223, 227 ,229, 233, 234, 235, 236, 237, 238\n",
    " ,239, 240 ,241 ,242, 243, 244, 245, 246, 247, 248, 249, 250, 252, 254, 257, 261, 262, 263\n",
    " ,264, 265 ,266 ,267, 268, 269, 270, 271, 272, 275, 276, 277, 278, 280, 281, 282, 283, 284\n",
    " ,285, 286 ,287 ,288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302\n",
    " ,303, 304 ,305 ,306, 309, 310, 312, 313, 314, 315, 316, 318, 319, 320, 321, 322, 323, 324\n",
    " ,325, 329 ,331 ,332, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344 ,345, 346, 348\n",
    " ,349, 351 ,354 ,355, 356, 357, 358, 359, 360, 362, 363, 364, 366, 367, 368 ,369, 370, 371\n",
    " ,372 ,373, 374, 376 ,377, 378 ,379 ,380, 381 ,382 ,383 ,384 ,385 ,386 ,387 ,388 ,389 ,390\n",
    " ,391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407 ,408\n",
    " ,409, 410, 411, 412, 413, 414, 415, 416, 425, 427, 428 ,429, 431]#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(f\"Neurons Overlaped Clusters {1} , {10}\")\n",
    "plt.show\n",
    "#plt.savefig(\"C:/Users/IC/Documents/PythonCampScript/Neuronoverlap1.png\",format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUYvTBQZ5o4t"
   },
   "outputs": [],
   "source": [
    "lo=[ 24 , 25  ,26,  30,  32 , 39 , 40,  41,  51,  52,  56,  57,  60,  80,  84,  90,  99, 101,\n",
    " 112, 124, 126, 133, 134, 137, 138, 140, 148 ,158, 182 ,185, 187 ,190, 202 ,203, 232 ,246,\n",
    " 253, 256, 261, 268, 269, 275, 286, 306, 312 ,321, 323 ,336, 337 ,338, 341 ,357, 369 ,373,\n",
    " 374, 375, 394, 400, 409, 410, 422, 427, 430 ,431, 433 ,435, 447]#idx_good\n",
    "io=[  8  ,12  ,17  ,22  ,23  ,25  ,28 , 41  ,53  ,57 , 62  ,69 , 72 , 73 , 74  ,76  ,77,  80,\n",
    " 115 ,116 ,123 ,129 ,139 ,145 ,183 ,184, 185 ,190 ,192, 193 ,194, 195, 222, 226 ,231 ,232,\n",
    " 253 ,255 ,256 ,258 ,259 ,260 ,279 ,308, 311 ,317 ,330, 333 ,350, 352, 353, 361 ,365 ,375,\n",
    " 417 ,418 ,419 ,421 ,422 ,423 ,426 ,430, 433]#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Neurons Overlaped\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26_HtQvH5o4y"
   },
   "outputs": [],
   "source": [
    "lo=[ 15,  16,  19,  20,  23,  27,  29,  48,  50,  55,  81,  93,  94,  97, 100, 125, 128, 135\n",
    " ,142, 143, 152, 163, 174, 178, 181, 184, 194, 195, 218, 230, 244, 254, 255, 257, 258, 259\n",
    " ,271, 274, 319, 322, 324, 326, 332, 367, 372, 379, 397, 405, 407, 448, 491, 492]\n",
    "#idx_good\n",
    "io=[ 39 , 46 , 71 , 75 ,109 ,114, 117, 125, 128, 197, 224 ,230 ,434]#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Neurons Overlaped\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wSLmAxmC5o43"
   },
   "outputs": [],
   "source": [
    "lo=[ 13,  14 , 17 , 46 , 92 , 98 ,170 ,179 ,233 ,252 ,263 ,265 ,325 ,327 ,402, 406 ,418 ,488\n",
    " ,489]\n",
    "#idx_good\n",
    "io=[  2  , 6  , 7  ,14  ,15 , 26 , 65,  86 ,307 ,326 ,327 ,347]\n",
    "#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Neurons Overlaped\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yxuBg7ad5o46"
   },
   "outputs": [],
   "source": [
    "lo=[ 21 , 22 , 82 , 96 ,129 ,168 ,169, 171, 172, 175 ,176 ,186 ,282 ,318 ,320 ,328 ,408, 486]\n",
    "\n",
    "#idx_good\n",
    "io=[  3 ,  4  ,13  ,66  ,68  ,70 ,113 ,228 ,251 ,432]\n",
    "\n",
    "#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Neurons Overlaped\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4uKi4SHw5o48"
   },
   "outputs": [],
   "source": [
    "lo=[ 45 ,260, 316, 370, 371 ,490]\n",
    "\n",
    "#idx_good\n",
    "io=[  9 ,118 ,119, 121, 188 ,424]\n",
    "\n",
    "\n",
    "#pidx_good\n",
    "for i in lo:\n",
    "    for k in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{i}_coord'][k,0]\n",
    "            ya = globals()[f'idx{i}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for i in io:\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "            ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "            plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "plt.title(\"Neurons Overlaped\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sl-9q3E35o4-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lti=np.arange(0,12,0.5)\n",
    "fig,ax = plt.subplots(2,1,figsize=(18,5))\n",
    "ax[0].set_xlim(0,12)\n",
    "ax[0].set_title(f'Pre Trauma Raw Trace Neuron index {lo}')\n",
    "ax[0].plot(np.linspace(0,12,10999+1),RawTraces[lo],c=\"r\")#DeconvTraces\n",
    "ax[0].set_xticks(lti)\n",
    "ax[1].set_xlim(0,12)\n",
    "ax[1].set_xticks(lti)\n",
    "ax[1].set_title(f'Pos Trauma Raw Trace Neuron index {i}')\n",
    "ax[1].plot(np.linspace(0,12,10999),PosRawTraces[i],c='#59A656')\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o27WYdTo5o5B"
   },
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(18,5))\n",
    "plt.plot(np.linspace(0,12,10999+1),RawTraces[lo],c='r')\n",
    "plt.plot(np.linspace(0,12,10999),PosRawTraces[lo],c='g')\n",
    "plt.xticks(lti)\n",
    "plt.xlim(0,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "pvjnk6Q05o5G"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,1)\n",
    "ax[0].set_xlim(2,7)\n",
    "ax[0].set_title('Pre Trauma Raw Trace')\n",
    "ax[0].plot(np.linspace(0,12,10999+1,30),RawTraces[13])#DeconvTraces\n",
    "ax[1].set_xlim(2,7)\n",
    "ax[1].set_title('Pos Trauma Raw Trace')\n",
    "ax[1].plot(np.linspace(0,12,10999,30),cnm.estimates.C[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JInVshPb5o5J"
   },
   "outputs": [],
   "source": [
    "print(RawTraces[8].max())\n",
    "print(idx_good[8])\n",
    "print(pidx_good[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "fEixf4AY5o5L"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(10, 5, figsize=(20, 10), constrained_layout=True)\n",
    "cont = 10\n",
    "x = np.linspace(0,1,10999)\n",
    "if cont<100:\n",
    "    for ax, index in zip(axs.flat, idx_good):\n",
    "        ax.set_title(f'ID={index}')\n",
    "        ax.plot(x, cnm.estimates.C[cont], lw=0.9)\n",
    "        cont +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "t7YklhlZ5o5Q"
   },
   "outputs": [],
   "source": [
    "i=163\n",
    "for i in range()\n",
    "for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "        xa1 = globals()[f'idx{i}_coord1'][j,0]\n",
    "        ya1 = globals()[f'idx{i}_coord1'][j,1]\n",
    "        plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "        plt.imshow(pnr1)\n",
    "print(len(globals()[f'idx{i}_coord1'][:,0]))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Ti5x4UI5o5T"
   },
   "outputs": [],
   "source": [
    "cln=np.array([])\n",
    "for l in range(200):\n",
    "    i=int(pidx_good[l])\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "        x1 = np.append(x1,globals()[f'idx{i}_coord1'][j,0])\n",
    "        y1 = np.append(y1,globals()[f'idx{i}_coord1'][j,1])\n",
    "    lo=idx_good[l]\n",
    "    for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        x = np.append(x,globals()[f'idx{lo}_coord'][k,0])\n",
    "        y = np.append(y,globals()[f'idx{lo}_coord'][k,1])\n",
    "\n",
    "    plt.scatter(x=x, y=y,s = 0.8, c= 'r' )\n",
    "    plt.scatter(x = x1,y=y1,s= 0.8, c='g')\n",
    "    plt.imshow(img1)\n",
    "    plt.title(f'NeuronPST Index:{i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0D2wHgc_5o5Y"
   },
   "outputs": [],
   "source": [
    "len(globals()[f'idx{163}_coord1'][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "aQkZmzGR5o5a"
   },
   "outputs": [],
   "source": [
    "CenterOfMass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S9WXthUw5o5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ra2=np.array([])\n",
    "x2=np.array([])\n",
    "y2=np.array([])\n",
    "\n",
    "for l in range(240):\n",
    "    i=int(pidx_good[l])\n",
    "    if (len(globals()[f'idx{i}_coord1'][:,0]))<=90 and(len(globals()[f'idx{i}_coord1'][:,0]))>=40:\n",
    "        ra2=np.append(ra2,i)\n",
    "print(ra2)\n",
    "\n",
    "for i in ra2:\n",
    "    i=int(i)\n",
    "    for j in range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "            x2 = np.append(x2,globals()[f'idx{i}_coord1'][j,0])\n",
    "            y2 = np.append(y2,globals()[f'idx{i}_coord1'][j,1])\n",
    "plt.scatter(x2,y2,s= 0.8, c='g')\n",
    "plt.imshow(img2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2zQknvr5o5f"
   },
   "outputs": [],
   "source": [
    "ra1=np.array([])\n",
    "ra1=np.expand_dims(ra1,axis=1)\n",
    "x1=np.array([])\n",
    "y1=np.array([])\n",
    "\n",
    "for l in range(240):\n",
    "    i=int(idx_good[l])\n",
    "    if (len(globals()[f'idx{i}_coord'][:,0]))<=90 and(len(globals()[f'idx{i}_coord'][:,0]))>=40:\n",
    "                ra1=np.append(ra1,i)\n",
    "print(ra1)\n",
    "\n",
    "for i in ra1:\n",
    "    i=int(i)\n",
    "    for j in range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "            x1 = np.append(x1,globals()[f'idx{i}_coord'][j,0])\n",
    "            y1 = np.append(y1,globals()[f'idx{i}_coord'][j,1])\n",
    "plt.scatter(x1,y1,s= 0.8, c='r')\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nOM2FwI5o5g"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x1,y1,s=0.8,c='r')\n",
    "plt.scatter(x2,y2,s=0.8,c='g')\n",
    "plt.imshow(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "f6zcUgjp5o5i"
   },
   "outputs": [],
   "source": [
    "ra1=np.array([1,2])\n",
    "ra1=ra1[:,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A5QHncsk5o5n"
   },
   "outputs": [],
   "source": [
    "res=np.array([])\n",
    "res2=np.array([])\n",
    "samepx1=np.array([])\n",
    "samepx2=np.array([])\n",
    "samepy1=np.array([])\n",
    "samepy2=np.array([])\n",
    "\n",
    "for k in range(len(x2)):\n",
    "        if x2[k]-x1[k]>=-5 and x2[k]-x2[k]<=5 and y2[k]-y1[k]>=-5 and y2[k]-y1[k]<=5:\n",
    "            samepx1=np.append(samepx1,x1[k])\n",
    "            samepy1=np.append(samepy1,y1[k])\n",
    "            samepx2=np.append(samepx2,x2[k])\n",
    "            samepy2=np.append(samepy2,y2[k])\n",
    "\n",
    "for i in ra1:\n",
    "    i=int(i)\n",
    "    for j in  range(len(globals()[f'idx{i}_coord'][:,0])):\n",
    "        for k in range(len(samepx1)):\n",
    "            if samepx1[k] ==globals()[f'idx{i}_coord'][j,0] and samepy1[k]==globals()[f'idx{i}_coord'][j,1]:\n",
    "                res=np.append(res,i)\n",
    "for i in ra2:\n",
    "    i=int(i)\n",
    "    for j in  range(len(globals()[f'idx{i}_coord1'][:,0])):\n",
    "        for k in range(len(samepx1)):\n",
    "            if samepx2[k] ==globals()[f'idx{i}_coord1'][j,0] and samepy2[k]==globals()[f'idx{i}_coord1'][j,1]:\n",
    "                res2=np.append(res2,i)\n",
    "res=np.unique(res)\n",
    "res2=np.unique(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lIUrBYAd5o5s"
   },
   "outputs": [],
   "source": [
    "print((res))\n",
    "print((res2))\n",
    "#print(idx_good[18])\n",
    "#print(pidx_good[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "cDrTaLTh5o5v"
   },
   "outputs": [],
   "source": [
    "nwg=np.array([])\n",
    "for i in idx_good:\n",
    "    i=int(i)\n",
    "    for j in range(len(res)):\n",
    "        if i==res[j]:\n",
    "            nwg=np.append(nwg,i)\n",
    "print(nwg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_3Dyl5w75o5y"
   },
   "outputs": [],
   "source": [
    "print(ra1)\n",
    "# 2.   3.   4.   5.   6.   8.   9.  10.  11.  12.  13.  16.  17.  19.\n",
    "  20.  22.  23.  24.  25.  27.  31.  39.  41.  42.  46.  47.  48.  49.\n",
    "  65.  67.  69.  72.  74.  76.  79.  93. 108. 116. 117. 123. 128. 132.\n",
    " 144. 223. 224. 225. 226. 231. 233. 234. 235. 239. 247. 251. 252. 254.\n",
    " 255. 256. 257. 258. 269. 271. 275. 279. 362. 365. 375."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgikaXJz5o51"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "samx=[8,14,28,81, 90,93,99,132,211,212,213,214,222,223,224,225,226,230,229]\n",
    "samy=[1,10,17,55,82,72,71,108,123,204,219,201,202,230]\n",
    "xy=[[8,1],[14,10],[28,17],[81,55],[90,82],[93,121],[132,108]]\n",
    "lo=idx_good[224]#8,14,28,81, ,90,93,99,132,,211,212,213,214,222,223,224,225,226,230,229\n",
    "io=pidx_good[218]#1,10,17,55,66,, 72,71,108,123,204,,,,,,,,,,,,219,201,202,       230\n",
    "#io=121 #for bad index use this\n",
    "#for i in range(len(samy)):\n",
    "tmp=[lo]#samx\n",
    "tmp1=[io]#samy\n",
    "\n",
    "#lo=idx_good[tmp]\n",
    "#io=pidx_good[tmp]\n",
    "for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        xa = globals()[f'idx{lo}_coord'][k,0]\n",
    "        ya = globals()[f'idx{lo}_coord'][k,1]\n",
    "        plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "for j in range(len(globals()[f'idx{io}_coord1'][:,0])):\n",
    "        xa1 = globals()[f'idx{io}_coord1'][j,0]\n",
    "        ya1 = globals()[f'idx{io}_coord1'][j,1]\n",
    "        plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "        plt.imshow(img2)#threshold\n",
    "        plt.title(f\"Neurons Overlaped Ids{lo,io}\")\n",
    "plt.show\n",
    "plt.savefig(f\"C:/Users/IC/Documents/PythonCampScript/Neuronoverlap{lo},{io}.png\",format=\"png\")\n",
    "#lti=np.arange(0,12,0.5)\n",
    "#Yti=np.arange(0,300,50)\n",
    "#fig,ax = plt.subplots(3,1,figsize=(20,10))\n",
    "#ax[0].set_xlim(0,12)\n",
    "#ax[0].set_ylim(-20,301)\n",
    "#ax[0].set_title(f'Pre Trauma Raw Trace Neuron index {lo}')\n",
    "#ax[0].plot(np.linspace(0,12,10999+1),RawTraces[lo],c=\"r\")#DeconvTraces\n",
    "#ax[0].set_xticks(lti)\n",
    "#ax[0].set_yticks(Yti)\n",
    "#ax[1].set_xlim(0,12)\n",
    "#ax[1].set_xticks(lti)\n",
    "#ax[1].set_yticks(Yti)\n",
    "#ax[1].set_ylim(-10,250)\n",
    "#ax[1].set_title(f'Pos Trauma Raw Trace Neuron index {io}')\n",
    "#ax[1].plot(np.linspace(0,12,10999),PosRawTraces[io],c='#59A656')\n",
    "\n",
    "#ax[2].set_xlim(0,12)\n",
    "#ax[2].set_ylim(-10,250)\n",
    "#ax[2].set_xticks(lti)\n",
    "#ax[2].set_yticks(Yti)\n",
    "#ax[2].set_title(f'Pre and Pos Trauma Raw Traces Neurons indexes{lo , io}')\n",
    "#ax[2].plot(np.linspace(0,12,10999+1),RawTraces[lo],c=\"r\")#DeconvTraces\n",
    "#ax[2].plot(np.linspace(0,12,10999),PosRawTraces[io],c='#59A656')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n",
    "#plt.savefig(f\"C:/Users/IC/Documents/PythonCampScript/Preliminarfig/ComparativeRawtraces{lo,i}.png\",format=\"png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rwuCNrHO5o52"
   },
   "outputs": [],
   "source": [
    "lo=13#idx_good[224]\n",
    "io=3#pidx_good[218]\n",
    "for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "        xa = globals()[f'idx{lo}_coord'][k,0]\n",
    "        ya = globals()[f'idx{lo}_coord'][k,1]\n",
    "        plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "\n",
    "for j in range(len(globals()[f'idx{io}_coord1'][:,0])):\n",
    "    xa1 = globals()[f'idx{io}_coord1'][j,0]\n",
    "    ya1 = globals()[f'idx{io}_coord1'][j,1]\n",
    "    plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "    plt.imshow(img1)#threshold\n",
    "    plt.title(f\"Neurons Overlaped Ids{lo,io}\")\n",
    "    plt.show\n",
    "plt.savefig(f\"C:/Users/IC/Documents/PythonCampScript/Preliminarfig/ComparativeRawtraces{lo,i}.svg\",format=\"svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qPDJpfkx5o6E"
   },
   "outputs": [],
   "source": [
    "img1cv=cv2.imread('C:/Users/IC/Documents/PythonCampScript/pretraumaResults/PnrResult.jpg',)\n",
    "img2cv=cv2.imread('C:/Users/IC/Documents/PythonCampScript/postraumaResults/PnrResult.jpg')\n",
    "\n",
    "gray1 = cv2.cvtColor(img1cv, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(img2cv, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.namedWindow('photo',cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('photo',400,300)\n",
    "dst = cv2.addWeighted(img1,0.7,img2cv,0.5,1)\n",
    "cv2.imshow('photo',dst)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LtZDQgRd5o6M",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M=cv2.moments(threshold1)\n",
    "print(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9J4xGo545o6O"
   },
   "outputs": [],
   "source": [
    "\n",
    "#_, threshold1 = cv2.threshold(imgc1, 121, 255, cv2.THRESH_BINARY)\n",
    "#_, threshold2 = cv2.threshold(imgc2,59, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "contours1, _ = cv2.findContours(img1cv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours2, _ = cv2.findContours(img2cv, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "# Find the centroids of each neuron\n",
    "centroids1 = []\n",
    "for contour in contours1:\n",
    "    M = cv2.moments(contour)\n",
    "    if (M['m00'] !=0):\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        centroids1.append((cx, cy))\n",
    "print(centroids1)\n",
    "\n",
    "centroids2 = []\n",
    "for contour in contours2:\n",
    "    if (M['m00'] !=0):\n",
    "        M = cv2.moments(contour)\n",
    "        cx = int(M['m10'] / M['m00'])\n",
    "        cy = int(M['m01'] / M['m00'])\n",
    "        centroids2.append((cx, cy))\n",
    "print(centroids2)\n",
    "\n",
    "\n",
    "# Overlay the two images\n",
    "vis = np.concatenate((img1, img2), axis=1)\n",
    "print(np.shape(vis))\n",
    "# Draw a line between the centroids of each pair of neurons\n",
    "for i in range(1):\n",
    "    #print('passou')len(centroids2)\n",
    "    for j in range():\n",
    "        cv2.line(vis, (centroids1[i][0]+ img1.shape[1], centroids1[i][1]), (centroids2[j][0] , centroids2[j][1]), (25, 0, 255), 1)\n",
    "# Show the overlayed image\n",
    "\n",
    "cv2.imshow(\"Neurons\", vis)\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qRcULxHe5o6Q"
   },
   "outputs": [],
   "source": [
    "print(np.max(RawTraces[lo]))\n",
    "print(np.max(cnm.estimates.C[i]))\n",
    "print(np.max(RawTraces[lo])-np.max(cnm.estimates.C[i]))\n",
    "\n",
    "#69,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a2_6fmtC5o6d"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,1,figsize=(18,5))\n",
    "ax[0].set_xlim(0,12)\n",
    "ax[0].set_title(f'Pre Trauma Raw Trace Neuron index {lo}')\n",
    "ax[0].plot(np.linspace(0,12,10999),cnm.estimates.C[9],c=\"r\")#DeconvTraces\n",
    "ax[1].set_xlim(0,12)\n",
    "ax[1].set_title(f'Pos Trauma Raw Trace Neuron index {i}')\n",
    "ax[1].plot(np.linspace(0,12,10999),cnm.estimates.C[72],c='#59A656')\n",
    "plt.subplots_adjust(wspace=0.2,hspace=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "X39YNqzl5o6o"
   },
   "outputs": [],
   "source": [
    "i=1\n",
    "for i in range(len(res)):\n",
    "    lo=idx_good[i]\n",
    "    for k in range(len(globals()[f'idx{lo}_coord'][:,0])):\n",
    "            xa = globals()[f'idx{lo}_coord'][k,0]\n",
    "            ya = globals()[f'idx{lo}_coord'][k,1]\n",
    "            plt.scatter(x=xa, y=ya,s = 0.8, c= 'r' )\n",
    "\n",
    "for i in range(len(res[0:61])):\n",
    "    ol=pidx_good[i]\n",
    "    for k in range(len(globals()[f'idx{ol}_coord1'][:,0])):\n",
    "                xa1 = globals()[f'idx{ol}_coord1'][k,0]\n",
    "                ya1 = globals()[f'idx{ol}_coord1'][k,1]\n",
    "                plt.scatter(x=xa1, y=ya1,s = 0.8, c= 'g' )\n",
    "plt.imshow(img1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNXETRd55o6r"
   },
   "outputs": [],
   "source": [
    "from matplotlib.transforms import (\n",
    "    Bbox, TransformedBbox, blended_transform_factory)\n",
    "from mpl_toolkits.axes_grid1.inset_locator import (\n",
    "    BboxPatch, BboxConnector, BboxConnectorPatch)\n",
    "\n",
    "\n",
    "def connect_bbox(bbox1, bbox2,\n",
    "                 loc1a, loc2a, loc1b, loc2b,\n",
    "                 prop_lines, prop_patches=None):\n",
    "    if prop_patches is None:\n",
    "        prop_patches = {\n",
    "            **prop_lines,\n",
    "            \"alpha\": prop_lines.get(\"alpha\", 1) * 0.2,\n",
    "            \"clip_on\": False,\n",
    "        }\n",
    "\n",
    "    c1 = BboxConnector(\n",
    "        bbox1, bbox2, loc1=loc1a, loc2=loc2a, clip_on=False, **prop_lines)\n",
    "    c2 = BboxConnector(\n",
    "        bbox1, bbox2, loc1=loc1b, loc2=loc2b, clip_on=False, **prop_lines)\n",
    "\n",
    "    bbox_patch1 = BboxPatch(bbox1, **prop_patches)\n",
    "    bbox_patch2 = BboxPatch(bbox2, **prop_patches)\n",
    "\n",
    "    p = BboxConnectorPatch(bbox1, bbox2,\n",
    "                           loc1a=loc1a, loc2a=loc2a, loc1b=loc1b, loc2b=loc2b,\n",
    "                           clip_on=False,\n",
    "                           **prop_patches)\n",
    "\n",
    "    return c1, c2, bbox_patch1, bbox_patch2, p\n",
    "\n",
    "\n",
    "def zoom_effect01(ax1, ax2, xmin, xmax, **kwargs):\n",
    "    \"\"\"\n",
    "    Connect *ax1* and *ax2*. The *xmin*-to-*xmax* range in both axes will\n",
    "    be marked.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax1\n",
    "        The main axes.\n",
    "    ax2\n",
    "        The zoomed axes.\n",
    "    xmin, xmax\n",
    "        The limits of the colored area in both plot axes.\n",
    "    **kwargs\n",
    "        Arguments passed to the patch constructor.\n",
    "    \"\"\"\n",
    "\n",
    "    bbox = Bbox.from_extents(xmin, 0, xmax, 1)\n",
    "\n",
    "    mybbox1 = TransformedBbox(bbox, ax1.get_xaxis_transform())\n",
    "    mybbox2 = TransformedBbox(bbox, ax2.get_xaxis_transform())\n",
    "\n",
    "    prop_patches = {**kwargs, \"ec\": \"none\", \"alpha\": 0.2}\n",
    "\n",
    "    c1, c2, bbox_patch1, bbox_patch2, p = connect_bbox(\n",
    "        mybbox1, mybbox2,\n",
    "        loc1a=3, loc2a=2, loc1b=4, loc2b=1,\n",
    "        prop_lines=kwargs, prop_patches=prop_patches)\n",
    "\n",
    "    ax1.add_patch(bbox_patch1)\n",
    "    ax2.add_patch(bbox_patch2)\n",
    "    ax2.add_patch(c1)\n",
    "    ax2.add_patch(c2)\n",
    "    ax2.add_patch(p)\n",
    "\n",
    "    return c1, c2, bbox_patch1, bbox_patch2, p\n",
    "\n",
    "\n",
    "def zoom_effect02(ax1,ax2, xmin, xmax , **kwargs):\n",
    "    \"\"\"\n",
    "    ax1 : the main axes\n",
    "    ax1 : the zoomed axes\n",
    "\n",
    "    Similar to zoom_effect01.  The xmin & xmax will be taken from the\n",
    "    ax1.viewLim.\n",
    "    \"\"\"\n",
    "\n",
    "    bbox = Bbox.from_extents(xmin, 0, xmax, 1)\n",
    "\n",
    "    mybbox1 = TransformedBbox(bbox, ax1.get_xaxis_transform())\n",
    "    mybbox2 = TransformedBbox(bbox, ax2.get_xaxis_transform())\n",
    "\n",
    "    prop_patches = {**kwargs, \"ec\": \"none\", \"alpha\": 0.2}\n",
    "\n",
    "    c1, c2, bbox_patch1, bbox_patch2, p = connect_bbox(\n",
    "        mybbox1, mybbox2,\n",
    "        loc1a=3, loc2a=2, loc1b=4, loc2b=1,\n",
    "        prop_lines=kwargs, prop_patches=prop_patches)\n",
    "\n",
    "    ax1.add_patch(bbox_patch1)\n",
    "    ax2.add_patch(bbox_patch2)\n",
    "    ax2.add_patch(c1)\n",
    "    ax2.add_patch(c2)\n",
    "    ax2.add_patch(p)\n",
    "\n",
    "    return c1, c2, bbox_patch1, bbox_patch2, p\n",
    "\n",
    "zoomyti=np.arange(4,7,0.5)\n",
    "axs = plt.figure(figsize=(15,5)).subplot_mosaic([\n",
    "    [\"main\",\"main2\"],\n",
    "    [\"zoom1\",\"zoom2\"]\n",
    "])\n",
    "\n",
    "axs[\"main\"].set(xlim=(0, 12))\n",
    "zoom_effect01( axs[\"main\"],axs[\"zoom1\"], 5,6.5)\n",
    "axs[\"main\"].set_xlim(0,12)\n",
    "axs[\"main\"].set_ylim(-50,300)\n",
    "axs[\"main\"].set_title('Pre Trauma Raw Trace')\n",
    "axs[\"main\"].plot(np.linspace(0,12,10999+1),RawTraces[13],c=\"#DB2607\",linewidth='0.8')#DeconvTraces\n",
    "axs[\"main\"].set_xlabel('Timestamp(Min)')\n",
    "axs[\"main\"].set_ylabel('Brightness')\n",
    "axs[\"main\"].set_yticks(Yti)\n",
    "\n",
    "axs[\"zoom1\"].set_xlim(4,7)\n",
    "axs[\"zoom1\"].set_ylim(-50,275)\n",
    "axs[\"zoom1\"].set_title('Pre Trauma Raw Trace zoomed')\n",
    "#axs[\"zoom1\"].set_xlabel('Timestamp(Min)')\n",
    "axs[\"zoom1\"].set_yticks(zoomyti)\n",
    "axs[\"zoom1\"].set_ylabel('Brightness')\n",
    "axs[\"zoom1\"].plot(np.linspace(0,12,10999+1),RawTraces[13],c=\"#DB2607\",linewidth='0.8')#DeconvTraces\n",
    "\n",
    "axs[\"main2\"].set(xlim=(0, 12))\n",
    "axs[\"main2\"].set(ylim=(-50, 300))\n",
    "zoom_effect02(axs[\"main2\"],axs[\"zoom2\"], 5,6.5)\n",
    "axs[\"main2\"].set_title('Pre Trauma Raw Trace')\n",
    "axs[\"main2\"].plot(np.linspace(0,12,10999),cnm.estimates.C[3],c='#59A656',linewidth='0.8')#DeconvTraces\n",
    "axs[\"main2\"].set_xlabel('Timestamp(Min)')\n",
    "axs[\"main2\"].set_ylabel('Brightness')\n",
    "axs[\"main2\"].set_yticks(Yti)\n",
    "axs[\"zoom2\"].set_yticks(zoomyti)\n",
    "axs[\"zoom2\"].set_xlim(4,7)\n",
    "axs[\"zoom2\"].set_ylim(-50,275)\n",
    "axs[\"zoom2\"].set_title('Post Trauma Raw Trace zoomed')\n",
    "axs[\"zoom2\"].set_ylabel('Brightness')\n",
    "axs[\"zoom2\"].plot(np.linspace(0,12,10999),cnm.estimates.C[3],c='#59A656',linewidth='0.8')#DeconvTraces\n",
    "#axs[\"zoom1\"]\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"C:/Users/IC/Documents/PythonCampScript/Comparativetraces.svg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAajZXsr5o6v"
   },
   "outputs": [],
   "source": [
    "SettingBasicpaths(r'C:/Users/IC\\Documents/PythonCampScript/pretrauma')\n",
    "GetArchives(True,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EU25lMo5o6z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T6qNSe7W5o63"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "F = h5py.File('C:/Users/IC/Documents/PythonCampScript/postraumaResults/analysis_results.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZF3XiwS_5o65"
   },
   "outputs": [],
   "source": [
    "#for key in F.keys():\n",
    "    #print(key) #Names of the root level object names in HDF5 file - can be groups or datasets.\n",
    "    #print(type(F[key])) # get the object type: usually group or dataset\n",
    "Dim=F['estimates']\n",
    "#for key in Dim.keys():\n",
    "    #print(key)\n",
    "\n",
    "# This assumes group[some_key_inside_the_group] is a dataset,\n",
    "# and returns a np.array:\n",
    "data = Dim['A']\n",
    "#Do whatever you want with data\n",
    "print(data)\n",
    "#After you are done\n",
    "#f.close()\n",
    "print(Dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qK06kzx5o7A"
   },
   "outputs": [],
   "source": [
    "print(Dim.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EUdCCu95o7C"
   },
   "outputs": [],
   "source": [
    "Vet=(Dim['A'])\n",
    "print(Vet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh1hpBEh5o7D"
   },
   "source": [
    "# Hdf5 read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CkvZP8eE5o7F",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nome_do_arquivo_hdf5 = r'C:/Users/IC\\Documents/PythonCampScript/postraumaResults/analysis_results.hdf5'\n",
    "\n",
    "f=h5py.File(nome_do_arquivo_hdf5, \"r\")\n",
    "print(f['estimates'])\n",
    "#print(['estimates']['S'])\n",
    "idx=(f['estimates']['S'][io])#get the deconv  S trace ALL\n",
    "lp=(f['estimates']['C'][io])#get the Raw trace ALL\n",
    "CodP=f['estimates']['A']['indices']#get the Neuronposi trace ALL\n",
    "\n",
    "xca=np.linspace(0,12,len(idx))\n",
    "plt.plot(xca,lp)\n",
    "#print(lp[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "SS4K6qEe5o7P"
   },
   "outputs": [],
   "source": [
    "EstHD=CodP\n",
    "PosRawTraces=f['estimates']['C']\n",
    "Dimensions1 = (np.shape(gray1))#images\n",
    "CenterOfMass = np.array([_['CoM'] for _ in visualization.get_contours(EstHD, Dimensions1)])\n",
    "CellsCoordinates = [_['coordinates'] for _ in visualization.get_contours(EstHD, Dimensions1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pOOAhT_u5o7e"
   },
   "outputs": [],
   "source": [
    "(CodP['indices'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "N4cxCSJX5o7f"
   },
   "outputs": [],
   "source": [
    "for index in range(len(lp)):#cnm.estimates.C\n",
    "    globals()[f'idx{index}_coordHD'] = CellsCoordinates[index]\n",
    "idx0_coord.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EPkbyI0T5o7n"
   },
   "outputs": [],
   "source": [
    "for j in range(len(globals()[f'idx{io}_coord1'][:,0])):\n",
    "        xa1 = globals()[f'idx{io}_coord1'][j,0]\n",
    "        ya1 = globals()[f'idx{io}_coord1'][j,1]\n",
    "        plt.scatter(x = xa1,y=ya1,s= 0.8, c='g')\n",
    "        plt.imshow(img2)#threshold\n",
    "        pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CoSoBbHd5o7q"
   },
   "outputs": [],
   "source": [
    "\n",
    "data=f['estimates']['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSFj09SQ5o7s"
   },
   "outputs": [],
   "source": [
    "print(f['estimates']['A'].keys())\n",
    "idx=(f['estimates']['A']['data'][()])\n",
    "print(len(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tO-ITstd5o7u"
   },
   "outputs": [],
   "source": [
    "print(f['estimates'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IgBm5Gh35o7x"
   },
   "source": [
    "# Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GOb414Ft5o7y"
   },
   "outputs": [],
   "source": [
    "\n",
    "vPre=(RawTraces[lo].max()-RawTraces[lo].min())\n",
    "vPos=(PosRawTraces[io].max()-PosRawTraces[io].min())\n",
    "#print(RawTraces[lo].mean()-RawTraces[lo].min())\n",
    "print((RawTraces[io].max()-PosRawTraces[io].max()))\n",
    "print(vPre-vPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfbRipgq5o70"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# Definir o n√∫mero de neur√¥nios\n",
    "NUM_NEURONS = len(idx_good)\n",
    "\n",
    "# Detectar bordas usando Canny\n",
    "#edges1 = cv2.Canny(threshold1, 100, 200)\n",
    "#edges2 = cv2.Canny(threshold2, 100, 200)\n",
    "#\n",
    "\n",
    "\n",
    "# Encontrar os contornos das bordas\n",
    "#contours1, hierarchy1 = cv2.findContours(edges1, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#contours2, hierarchy2 = cv2.findContours(edges2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Fazer o clustering usando KMeans\n",
    "cluster1 = KMeans(n_clusters=NUM_NEURONS, random_state=None ).fit(RawTraces)\n",
    "#cluster2 = KMeans(n_clusters=NUM_NEURONS, random_state=None).fit(np.array([cnt[0][0] for cnt in contours2]))\n",
    "\n",
    "NeuronsFound1=((cluster1.labels_))\n",
    "print(NeuronsFound1)\n",
    "#NeuronsFound2=(len(cluster2.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02BpIF-O5o74"
   },
   "outputs": [],
   "source": [
    "clustert = KMeans(n_clusters=NUM_NEURONS, random_state=None ).fit_predict(RawTraces)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ISmz83WO5o79"
   },
   "outputs": [],
   "source": [
    "label=(np.unique(clustert))\n",
    "for i in label:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iw-TB9qD5o8A"
   },
   "outputs": [],
   "source": [
    "print(len(idx_good))\n",
    "print(len(NeuronsFound1))\n",
    "plt.scatter(np.arange(0,len(NeuronsFound1)),NeuronsFound1,cmap='viridis')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": [
    {
     "file_id": "19LezMMoKrwWqY4jqmIb5HS105iYygGhm",
     "timestamp": 1671120751882
    },
    {
     "file_id": "1-Ur4cNiHAvi6OFOxKtY3223708hOIpaO",
     "timestamp": 1627477434162
    },
    {
     "file_id": "1Xz2ekcpnF2oHH5TIn99uHR4GT_AvhaXZ",
     "timestamp": 1626300502174
    },
    {
     "file_id": "1lTOcSdd2oGhmZE666IqPbfSqMaMdf7Sb",
     "timestamp": 1625709153344
    },
    {
     "file_id": "1bpLITBLHEtiJqYYCAO2wbJUjdI6EeB2o",
     "timestamp": 1625591658210
    },
    {
     "file_id": "1yldcP5KBY7x8aJB-fwklUeoNDyNWQvZ-",
     "timestamp": 1625582956019
    },
    {
     "file_id": "1nuHWPoCBNszRJ1gihBRh8WR5IwgzdlUt",
     "timestamp": 1625422055616
    },
    {
     "file_id": "14o3OiJhQoo2t8ooDBR82eKr6ZZcQjssR",
     "timestamp": 1625414321650
    },
    {
     "file_id": "1vkp-uPV8tKavmX12bcN2L-jYH8_MgmHL",
     "timestamp": 1625270602812
    },
    {
     "file_id": "1vEW765UB98tsTTPkPqqtLk_xxABBQUQO",
     "timestamp": 1582320357918
    }
   ]
  },
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
